{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJm_b_4vE5uK"
      },
      "source": [
        "# Environment Setup for Soccer Tracking Pipeline\n",
        "\n",
        "This notebook helps you set up the environment for running the soccer tracking pipeline on Google Colab with remote VM access via VS Code SSH."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dURJtSYE5uO"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rtVmV1NwE5uR",
        "outputId": "88a97e98-d172-4c8c-c301-5a82872f68b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch with CUDA support (automatically detects available CUDA version)\n",
        "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F4wlPzIwE5uS",
        "outputId": "9c2011ac-5fea-459f-cfac-1b85eca25407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.166-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting boxmot\n",
            "  Downloading boxmot-13.0.17-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting bayesian-optimization>=2.0.4 (from boxmot)\n",
            "  Downloading bayesian_optimization-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filterpy<2.0.0,>=1.4.5 (from boxmot)\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0.0,>=6.1.3 (from boxmot)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from boxmot) (5.2.0)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.42 in /usr/local/lib/python3.11/dist-packages (from boxmot) (3.1.44)\n",
            "Collecting lapx<1.0.0,>=0.5.5 (from boxmot)\n",
            "  Downloading lapx-0.5.11.post1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting loguru<1.0.0,>=0.7.2 (from boxmot)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mplcursors>=0.6 (from boxmot)\n",
            "  Downloading mplcursors-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pyqt5>=5.15.11 (from boxmot)\n",
            "  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: regex<2025.0.0,>=2024.0.0 in /usr/local/lib/python3.11/dist-packages (from boxmot) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from boxmot) (1.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from boxmot) (75.2.0)\n",
            "Collecting yacs<1.0.0,>=0.1.8 (from boxmot)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting colorama<1.0.0,>=0.4.6 (from bayesian-optimization>=2.0.4->boxmot)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0.0,>=6.1.3->boxmot) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot) (3.18.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4.0.0,>=3.1.42->boxmot) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Collecting PyQt5-sip<13,>=12.15 (from pyqt5>=5.15.11->boxmot)\n",
            "  Downloading PyQt5_sip-12.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (472 bytes)\n",
            "Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from pyqt5>=5.15.11->boxmot)\n",
            "  Downloading PyQt5_Qt5-5.15.17-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.9)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->boxmot) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->boxmot) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.42->boxmot) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown<6.0.0,>=5.1.0->boxmot) (2.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot) (1.7.1)\n",
            "Downloading ultralytics-8.3.166-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boxmot-13.0.17-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bayesian_optimization-3.0.1-py3-none-any.whl (36 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lapx-0.5.11.post1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mplcursors-0.6-py3-none-any.whl (20 kB)\n",
            "Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading PyQt5_Qt5-5.15.17-py3-none-manylinux2014_x86_64.whl (61.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQt5_sip-12.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=64e5a2e501fa0ac28267dad798b2542ec9877cde045f8f8d68ddee2ad5a0e123\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/dc/3c/e12983eac132d00f82a20c6cbe7b42ce6e96190ef8fa2d15e1\n",
            "Successfully built filterpy\n",
            "Installing collected packages: PyQt5-Qt5, yacs, PyQt5-sip, loguru, lapx, ftfy, colorama, pyqt5, mplcursors, filterpy, bayesian-optimization, ultralytics-thop, ultralytics, boxmot\n",
            "Successfully installed PyQt5-Qt5-5.15.17 PyQt5-sip-12.17.0 bayesian-optimization-3.0.1 boxmot-13.0.17 colorama-0.4.6 filterpy-1.4.5 ftfy-6.3.1 lapx-0.5.11.post1 loguru-0.7.3 mplcursors-0.6 pyqt5-5.15.11 ultralytics-8.3.166 ultralytics-thop-2.0.14 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# Install computer vision and tracking libraries\n",
        "!pip install ultralytics boxmot opencv-python numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "muj9X2h-E5uT",
        "outputId": "0401b4f8-e214-4b03-ed7b-6c5213115738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for trackeval (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install evaluation library\n",
        "!pip install -q git+https://github.com/JonathonLuiten/TrackEval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UPVCUKVdE5uT",
        "outputId": "23041099-6f00-430a-8333-66d230e4254d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install additional utilities\n",
        "!pip install tqdm matplotlib pandas pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ifu3BwIE5uU"
      },
      "source": [
        "## 2. Mount Google Drive (for data access)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#THIS CREATED A ZIP DATASET IN MY DRIVE\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "# Path to the folder you want to zip in your Google Drive\n",
        "folder_to_zip = '/content/drive/MyDrive/SOCCER_DATA'\n",
        "\n",
        "# Change this line to save the zip file back to your Drive\n",
        "# This will save it in the main \"My Drive\" folder.\n",
        "output_zip_name = '/content/drive/MyDrive/SOCCER_DATA'\n",
        "# -------------------\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_to_zip):\n",
        "  print(f\"Error: The folder '{folder_to_zip}' was not found.\")\n",
        "  print(\"Please make sure the folder path is correct and that your Drive is mounted.\")\n",
        "else:\n",
        "  print(f\"Found folder: {folder_to_zip}. Starting to create zip file...\")\n",
        "\n",
        "  # Create the zip file from the specified folder\n",
        "  # The output file will now be saved to your Google Drive\n",
        "  shutil.make_archive(output_zip_name, 'zip', folder_to_zip)\n",
        "\n",
        "  print(\"\\n✅ Success!\")\n",
        "  print(f\"The zip file '{os.path.basename(output_zip_name)}.zip' has been created successfully in your Google Drive.\")\n"
      ],
      "metadata": {
        "id": "8Fyow3aEWYZf",
        "outputId": "53125b00-1135-44f9-e5c5-8479f7637e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found folder: /content/drive/MyDrive/SOCCER_DATA. Starting to create zip file...\n",
            "\n",
            "✅ Success!\n",
            "The zip file 'SOCCER_DATA.zip' has been created successfully in your Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA1FlY7qE5uU",
        "outputId": "35a96b4b-faf4-451a-bdf8-50dd761ef71e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully!\n",
            "Soccer data found at: /content/drive/MyDrive/SOCCER_DATA\n",
            "Available datasets:\n",
            "  - deepsort_dataset_train\n",
            "  - deepsort_dataset_test\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for dataset access\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully!\")\n",
        "\n",
        "    # Check if soccer data exists\n",
        "    import os\n",
        "    gdrive_path = \"/content/drive/MyDrive/SOCCER_DATA\"\n",
        "    if os.path.exists(gdrive_path):\n",
        "        print(f\"Soccer data found at: {gdrive_path}\")\n",
        "        print(\"Available datasets:\")\n",
        "        for item in os.listdir(gdrive_path):\n",
        "            print(f\"  - {item}\")\n",
        "    else:\n",
        "        print(f\"No soccer data found at: {gdrive_path}\")\n",
        "        print(\"Please upload your dataset to Google Drive first.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Not running in Google Colab. Skipping drive mount.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMHLyxYQE5uU"
      },
      "source": [
        "## 3. Set Up the Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LmE7TrZ_E5uV",
        "outputId": "304f230f-4ebb-4420-aacb-f2a6a58989f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/yolo2'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 96 (delta 44), reused 46 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (96/96), 92.85 KiB | 1.89 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "/content/yolo2\n",
            "Collecting git+https://github.com/JonathonLuiten/TrackEval.git (from -r requirements.txt (line 13))\n",
            "  Cloning https://github.com/JonathonLuiten/TrackEval.git to /tmp/pip-req-build-5scrhygx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JonathonLuiten/TrackEval.git /tmp/pip-req-build-5scrhygx\n",
            "  Resolved https://github.com/JonathonLuiten/TrackEval.git to commit 12c8791b303e0a0b50f753af204249e622d0281a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.15.3)\n",
            "Requirement already satisfied: opencv-python>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
            "Requirement already satisfied: ultralytics>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (8.3.166)\n",
            "Requirement already satisfied: boxmot>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (13.0.17)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.10.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (6.0.2)\n",
            "Requirement already satisfied: pytest>=7.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (8.3.5)\n",
            "Collecting black>=23.0.0 (from -r requirements.txt (line 23))\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8>=6.0.0 (from -r requirements.txt (line 24))\n",
            "  Downloading flake8-7.3.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.0->-r requirements.txt (line 9)) (2.32.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.0->-r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.0->-r requirements.txt (line 9)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.0.0->-r requirements.txt (line 9)) (2.0.14)\n",
            "Requirement already satisfied: bayesian-optimization>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (3.0.1)\n",
            "Requirement already satisfied: filterpy<2.0.0,>=1.4.5 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (1.4.5)\n",
            "Requirement already satisfied: ftfy<7.0.0,>=6.1.3 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (6.3.1)\n",
            "Requirement already satisfied: gdown<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (5.2.0)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.42 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (3.1.44)\n",
            "Requirement already satisfied: lapx<1.0.0,>=0.5.5 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (0.5.11.post1)\n",
            "Requirement already satisfied: loguru<1.0.0,>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (0.7.3)\n",
            "Requirement already satisfied: mplcursors>=0.6 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (0.6)\n",
            "Requirement already satisfied: pyqt5>=5.15.11 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (5.15.11)\n",
            "Requirement already satisfied: regex<2025.0.0,>=2024.0.0 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (75.2.0)\n",
            "Requirement already satisfied: yacs<1.0.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from boxmot>=10.0.0->-r requirements.txt (line 10)) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 18)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 18)) (2025.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 22)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 22)) (1.6.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black>=23.0.0->-r requirements.txt (line 23)) (8.2.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.0.0->-r requirements.txt (line 23))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.0.0->-r requirements.txt (line 23))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black>=23.0.0->-r requirements.txt (line 23)) (4.3.8)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8>=6.0.0->-r requirements.txt (line 24))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pycodestyle<2.15.0,>=2.14.0 (from flake8>=6.0.0->-r requirements.txt (line 24))\n",
            "  Downloading pycodestyle-2.14.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting pyflakes<3.5.0,>=3.4.0 (from flake8>=6.0.0->-r requirements.txt (line 24))\n",
            "  Downloading pyflakes-3.4.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: colorama<1.0.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization>=2.0.4->boxmot>=10.0.0->-r requirements.txt (line 10)) (0.4.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0.0,>=6.1.3->boxmot>=10.0.0->-r requirements.txt (line 10)) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot>=10.0.0->-r requirements.txt (line 10)) (4.13.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4.0.0,>=3.1.42->boxmot>=10.0.0->-r requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.15 in /usr/local/lib/python3.11/dist-packages (from pyqt5>=5.15.11->boxmot>=10.0.0->-r requirements.txt (line 10)) (12.17.0)\n",
            "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in /usr/local/lib/python3.11/dist-packages (from pyqt5>=5.15.11->boxmot>=10.0.0->-r requirements.txt (line 10)) (5.15.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements.txt (line 9)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics>=8.0.0->-r requirements.txt (line 9)) (2025.7.9)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->boxmot>=10.0.0->-r requirements.txt (line 10)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->boxmot>=10.0.0->-r requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.42->boxmot>=10.0.0->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown<6.0.0,>=5.1.0->boxmot>=10.0.0->-r requirements.txt (line 10)) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot>=10.0.0->-r requirements.txt (line 10)) (1.7.1)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flake8-7.3.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pycodestyle-2.14.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading pyflakes-3.4.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyflakes, pycodestyle, pathspec, mypy-extensions, mccabe, flake8, black\n",
            "Successfully installed black-25.1.0 flake8-7.3.0 mccabe-0.7.0 mypy-extensions-1.1.0 pathspec-0.12.1 pycodestyle-2.14.0 pyflakes-3.4.0\n"
          ]
        }
      ],
      "source": [
        "# Clone your repository if it's not already present\n",
        "import os\n",
        "\n",
        "# Define the project directory name\n",
        "project_dir = '/content/yolo2'\n",
        "\n",
        "if not os.path.exists(project_dir):\n",
        "    # Clone the correct repository\n",
        "    !git clone https://github.com/victornaguiar/yolo2.git {project_dir}\n",
        "\n",
        "# Change the current directory to your project directory\n",
        "%cd {project_dir}\n",
        "\n",
        "# Install project dependencies from your requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOs88ASPE5uV"
      },
      "source": [
        "## 4. Verify Installation and Hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9oiON_aoE5uW",
        "outputId": "2734b6f0-ae5f-4997-cdb8-acb9b46eba9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "=== Hardware Information ===\n",
            "Python version: 2.6.0+cu124\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "GPU count: 1\n",
            "  GPU 0: NVIDIA A100-SXM4-40GB (39.6 GB)\n",
            "\n",
            "=== Library Versions ===\n",
            "OpenCV version: 4.12.0\n",
            "NumPy version: 2.0.2\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 74.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO model loaded successfully\n",
            "BotSORT not available - install with: pip install boxmot\n",
            "\n",
            "✓ All core libraries loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check hardware and installations\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"=== Hardware Information ===\")\n",
        "print(f\"Python version: {torch.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
        "        print(f\"  GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "\n",
        "print(f\"\\n=== Library Versions ===\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "# Test YOLO\n",
        "try:\n",
        "    model = YOLO('yolov8n.pt')\n",
        "    print(f\"YOLO model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading YOLO: {e}\")\n",
        "\n",
        "# Test BotSort\n",
        "try:\n",
        "    from boxmot import BotSORT\n",
        "    print(f\"BotSORT available\")\n",
        "except ImportError:\n",
        "    print(f\"BotSORT not available - install with: pip install boxmot\")\n",
        "\n",
        "print(\"\\n✓ All core libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3VHgRrsE5uW"
      },
      "source": [
        "## 5. Download Sample Data and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vJPBmnqnE5uX",
        "outputId": "94cd944c-53bb-4517-dfd2-9748e2803da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading YOLO models...\n",
            "Downloading yolov8n.pt...\n",
            "Downloading: 100% 6.53M/6.53M [00:00<00:00, 79.5MB/s]\n",
            "Downloaded: /content/yolo2/models/yolov8n.pt\n",
            "✓ Downloaded yolov8n.pt\n",
            "Downloading yolov8s.pt...\n",
            "Downloading: 100% 22.6M/22.6M [00:00<00:00, 155MB/s] \n",
            "Downloaded: /content/yolo2/models/yolov8s.pt\n",
            "✓ Downloaded yolov8s.pt\n",
            "Downloading yolov8m.pt...\n",
            "Downloading: 100% 52.1M/52.1M [00:00<00:00, 86.7MB/s]\n",
            "Downloaded: /content/yolo2/models/yolov8m.pt\n",
            "✓ Downloaded yolov8m.pt\n",
            "Downloading yolov8l.pt...\n",
            "Downloading: 100% 87.8M/87.8M [00:00<00:00, 100MB/s] \n",
            "Downloaded: /content/yolo2/models/yolov8l.pt\n",
            "✓ Downloaded yolov8l.pt\n",
            "Downloading yolov8x.pt...\n",
            "Downloading: 100% 137M/137M [00:00<00:00, 256MB/s]\n",
            "Downloaded: /content/yolo2/models/yolov8x.pt\n",
            "✓ Downloaded yolov8x.pt\n",
            "Downloading sample video...\n",
            "Error downloading https://github.com/mikel-brostrom/yolov8_tracking/raw/main/data/videos/people.mp4: HTTP Error 404: Not Found\n",
            "✗ Failed to download sample video\n",
            "\n",
            "Download complete!\n"
          ]
        }
      ],
      "source": [
        "# Download sample data and models\n",
        "!python scripts/download_models.py --all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNDJQTi_E5uX"
      },
      "source": [
        "## 6. Set Up SSH for Remote Development (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P2DdCHzSE5uX",
        "outputId": "b194de85-d830-438d-a649-45bf7232d887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSH setup ready. To connect VS Code remotely, run:\n",
            "\n",
            "from colab_ssh import launch_ssh_cloudflared\n",
            "launch_ssh_cloudflared(password='your_secure_password')\n",
            "\n",
            "Then follow the instructions to connect VS Code.\n"
          ]
        }
      ],
      "source": [
        "# Install and configure SSH for VS Code remote development\n",
        "!pip install colab-ssh -q\n",
        "\n",
        "print(\"SSH setup ready. To connect VS Code remotely, run:\")\n",
        "print(\"\")\n",
        "print(\"from colab_ssh import launch_ssh_cloudflared\")\n",
        "print(\"launch_ssh_cloudflared(password='your_secure_password')\")\n",
        "print(\"\")\n",
        "print(\"Then follow the instructions to connect VS Code.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOUuixoxE5uX"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run this cell to start SSH server\n",
        "# from colab_ssh import launch_ssh_cloudflared\n",
        "# launch_ssh_cloudflared(password=\"your_secure_password_here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyGW4h5lE5uY"
      },
      "source": [
        "## 7. Copy Dataset from Google Drive to Local Storage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# --- Configuration ---\n",
        "# Path to your zip file in Google Drive\n",
        "zip_file_path_in_drive = '/content/drive/MyDrive/SOCCER_DATA.zip'\n",
        "\n",
        "# Where to store the dataset in the Colab VM's local storage\n",
        "local_data_path = '/content/'\n",
        "# -------------------\n",
        "\n",
        "print(\"--- Step 1: Copying SOCCER_DATA.zip to the local VM's SSD ---\")\n",
        "print(f\"Source: {zip_file_path_in_drive}\")\n",
        "\n",
        "# Check if the zip file actually exists in Drive before we start\n",
        "if not os.path.exists(zip_file_path_in_drive):\n",
        "    print(f\"\\n❌ ERROR: The file '{os.path.basename(zip_file_path_in_drive)}' was not found in your Google Drive.\")\n",
        "    print(\"Please make sure the zipping process was successful and the file is in the correct location.\")\n",
        "else:\n",
        "    # --- Copy the file ---\n",
        "    start_time = time.time()\n",
        "    !cp \"{zip_file_path_in_drive}\" \"{local_data_path}\"\n",
        "    end_time = time.time()\n",
        "    print(f\"✅ Copy complete. Time taken: {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    # --- Unzip the file ---\n",
        "    local_zip_file = os.path.join(local_data_path, 'SOCCER_DATA.zip')\n",
        "    print(f\"\\n--- Step 2: Unzipping the dataset to '{local_data_path}' ---\")\n",
        "    start_time = time.time()\n",
        "    # The -q flag makes the unzip process \"quiet\" to avoid printing every single filename\n",
        "    !unzip -q \"{local_zip_file}\" -d \"{local_data_path}\"\n",
        "    end_time = time.time()\n",
        "    print(f\"✅ Unzip complete. Time taken: {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    # --- Verification ---\n",
        "    unzipped_folder_path = os.path.join(local_data_path, 'SOCCER_DATA')\n",
        "    if os.path.exists(unzipped_folder_path):\n",
        "        print(f\"\\n🎉 Success! The dataset is now ready for use at: {unzipped_folder_path}\")\n",
        "    else:\n",
        "        print(\"\\n❌ ERROR: Something went wrong during the unzip process.\")\n",
        "        print(\"The folder 'SOCCER_DATA' was not found after unzipping.\")\n",
        "\n",
        "    # Optional: Clean up the zip file to save space on the VM's disk\n",
        "    # print(\"\\n--- Step 3: Cleaning up the zip file ---\")\n",
        "    # !rm \"{local_zip_file}\"\n",
        "    # print(\"✅ Zip file removed.\")\n"
      ],
      "metadata": {
        "id": "KtSdVsqbiTZt",
        "outputId": "84575983-d7ab-40e5-96c3-6d114807e06b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Copying SOCCER_DATA.zip to the local VM's SSD ---\n",
            "Source: /content/drive/MyDrive/SOCCER_DATA.zip\n",
            "✅ Copy complete. Time taken: 76.19 seconds.\n",
            "\n",
            "--- Step 2: Unzipping the dataset to '/content/' ---\n",
            "✅ Unzip complete. Time taken: 169.01 seconds.\n",
            "\n",
            "❌ ERROR: Something went wrong during the unzip process.\n",
            "The folder 'SOCCER_DATA' was not found after unzipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiaADoHsE5uY",
        "outputId": "84550f5d-126e-4860-99a8-4821daf1515a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying dataset from Google Drive to local SSD...\n",
            "Source: /content/drive/MyDrive/SOCCER_DATA/deepsort_dataset_train\n",
            "Destination: /content/soccer_dataset\n",
            "Dataset copied successfully!\n",
            "\n",
            "Dataset structure:\n",
            "soccer_dataset/\n",
            "  tracking_results/\n",
            "    SNMOT-098.txt\n",
            "    SNMOT-153.txt\n",
            "    SNMOT-065.txt\n",
            "    SNMOT-160.txt\n",
            "    SNMOT-070.txt\n",
            "    ... and 52 more files\n",
            "  sequences/\n",
            "    SNMOT-164/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-099/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-107/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-075/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-158/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-160/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-166/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-068/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-103/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-073/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-165/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-155/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-159/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-108/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-063/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-169/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-168/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-105/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-077/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-076/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-102/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-061/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-109/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-162/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-154/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-064/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-060/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-115/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-069/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-070/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-062/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-098/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-152/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-167/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-106/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-153/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-104/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-170/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-113/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-072/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-163/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-161/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-151/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-111/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-157/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-067/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-114/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-097/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-071/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-066/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-065/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-156/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-101/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-112/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-110/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-100/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "    SNMOT-074/\n",
            "      000446.jpg\n",
            "      000559.jpg\n",
            "      000153.jpg\n",
            "      000420.jpg\n",
            "      000342.jpg\n",
            "      ... and 746 more files\n",
            "  detections/\n",
            "    SNMOT-098.txt\n",
            "    SNMOT-153.txt\n",
            "    SNMOT-065.txt\n",
            "    SNMOT-160.txt\n",
            "    SNMOT-070.txt\n",
            "    ... and 52 more files\n"
          ]
        }
      ],
      "source": [
        "# Copy dataset from Google Drive to local SSD for faster access\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "gdrive_dataset = \"/content/drive/MyDrive/SOCCER_DATA/deepsort_dataset_train\"\n",
        "local_dataset = \"/content/soccer_dataset\"\n",
        "\n",
        "if os.path.exists(gdrive_dataset):\n",
        "    print(f\"Copying dataset from Google Drive to local SSD...\")\n",
        "    print(f\"Source: {gdrive_dataset}\")\n",
        "    print(f\"Destination: {local_dataset}\")\n",
        "\n",
        "    if os.path.exists(local_dataset):\n",
        "        print(\"Local dataset already exists. Skipping copy.\")\n",
        "    else:\n",
        "        shutil.copytree(gdrive_dataset, local_dataset)\n",
        "        print(\"Dataset copied successfully!\")\n",
        "\n",
        "    # Verify dataset structure\n",
        "    print(\"\\nDataset structure:\")\n",
        "    for root, dirs, files in os.walk(local_dataset):\n",
        "        level = root.replace(local_dataset, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:5]:  # Show first 5 files only\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"{subindent}... and {len(files) - 5} more files\")\n",
        "else:\n",
        "    print(f\"Dataset not found at: {gdrive_dataset}\")\n",
        "    print(\"Please upload your dataset to Google Drive first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4njH2ic6E5uY"
      },
      "source": [
        "## 8. Test the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8N6jHlQGE5uY",
        "outputId": "96f77c1f-e35d-4321-af50-82295c43d47c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolo2\n",
            "Current working directory: /content/yolo2\n",
            "Python is now looking for modules in: /content/yolo2\n",
            "\n",
            "Installing boxmot...\n",
            "\n",
            "Downloading sample video...\n",
            "Video downloaded to 'data/sample_videos/people.mp4'\n",
            "\n",
            "Running a quick test of the tracking pipeline...\n",
            "Warning: boxmot not available. Install with: pip install boxmot\n",
            "YOLO tracker initialized with yolov8n.pt on cuda\n",
            "Processing first 100 frames of sample video...\n",
            "\n",
            "✓ Pipeline test completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# --- Definitive Fix for ModuleNotFoundError & FileNotFoundError ---\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. Define the project directory\n",
        "project_dir = '/content/yolo2'\n",
        "\n",
        "# 2. Change the current working directory (good practice)\n",
        "%cd {project_dir}\n",
        "\n",
        "# 3. Add the project directory to Python's path (CRITICAL STEP)\n",
        "if project_dir not in sys.path:\n",
        "    sys.path.insert(0, project_dir)\n",
        "\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Python is now looking for modules in: {sys.path[0]}\")\n",
        "\n",
        "# 4. Install the missing dependency\n",
        "print(\"\\nInstalling boxmot...\")\n",
        "!pip install -q boxmot\n",
        "\n",
        "# 5. Download the sample video (FIX for FileNotFoundError)\n",
        "print(\"\\nDownloading sample video...\")\n",
        "sample_video_path = 'data/sample_videos/people.mp4'\n",
        "if not os.path.exists(sample_video_path):\n",
        "    os.makedirs(os.path.dirname(sample_video_path), exist_ok=True)\n",
        "    # Download a sample video of people walking\n",
        "    !wget -q -O {sample_video_path} \"https://videos.pexels.com/video-files/853881/853881-sd_640_360_30fps.mp4\"\n",
        "    print(f\"Video downloaded to '{sample_video_path}'\")\n",
        "else:\n",
        "    print(\"Sample video already exists.\")\n",
        "\n",
        "\n",
        "# --- Original code from the cell below (with fixes) ---\n",
        "print(\"\\nRunning a quick test of the tracking pipeline...\")\n",
        "from src.tracking import YOLOTracker\n",
        "import cv2\n",
        "\n",
        "if os.path.exists(sample_video_path):\n",
        "    # Initialize tracker and video stream\n",
        "    tracker = YOLOTracker(model_name='yolov8n.pt')\n",
        "    cap = cv2.VideoCapture(sample_video_path)\n",
        "    frame_count = 0\n",
        "\n",
        "    print(\"Processing first 100 frames of sample video...\")\n",
        "    while cap.isOpened() and frame_count < 100:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # The tracker expects a list of detections, but for a quick test,\n",
        "        # we can pass None and it will perform detection internally.\n",
        "        tracks = tracker.update(None, frame)\n",
        "        print(f\"Frame {frame_count}: {len(tracks)} tracks detected\")\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(\"\\n✓ Pipeline test completed successfully!\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ ERROR: Sample video not found at: {sample_video_path}\")\n",
        "    print(\"Please make sure you have run the setup cells correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"it's over anakin, i have the high ground \\nyou underestimate my power \\ndon't try it\")"
      ],
      "metadata": {
        "id": "dhUl3I01ZOHy",
        "outputId": "282063d2-5293-4dad-cf82-71ff338e741e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it's over anakin, i have the high ground \n",
            "you underestimate my power \n",
            "don't try it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvmVpFq5E5uZ"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Your environment is now set up! You can:\n",
        "\n",
        "1. **Run the simple tracking demo**: Open `02_simple_tracking_demo.ipynb`\n",
        "2. **Process soccer datasets**: Open `03_soccer_tracking_pipeline.ipynb`\n",
        "3. **Evaluate results**: Open `04_evaluation_analysis.ipynb`\n",
        "4. **Use command-line scripts**:\n",
        "   - Track videos: `python scripts/run_tracking.py --help`\n",
        "   - Evaluate results: `python scripts/evaluate_results.py --help`\n",
        "\n",
        "### For Remote Development:\n",
        "- Connect VS Code using the SSH tunnel created above\n",
        "- Access files on the VM's SSD for fast processing\n",
        "- Leverage GPU acceleration automatically\n",
        "\n",
        "### Performance Tips:\n",
        "- Use the local SSD (`/content/`) for active datasets\n",
        "- Keep original data on Google Drive for backup\n",
        "- Monitor GPU memory usage with `nvidia-smi`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV7GW4MkHYlv"
      },
      "source": [
        "# Simple Tracking Demo\n",
        "\n",
        "This notebook demonstrates basic object tracking using the soccer tracking pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADB_YzI9HYlv"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DlFzYh4HYlw"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Video, display\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('..')\n",
        "\n",
        "from src.tracking import YOLOTracker, BotSortTracker\n",
        "from src.data import VideoGenerator\n",
        "from src.utils.visualization import draw_tracks\n",
        "from src.utils.file_utils import download_file, ensure_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuphH8YgHYlw"
      },
      "source": [
        "## 2. Download Sample Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xPsU8RXHYlx"
      },
      "outputs": [],
      "source": [
        "# Ensure we have a sample video\n",
        "sample_video_path = \"../data/sample_videos/people.mp4\"\n",
        "sample_video_url = \"https://github.com/mikel-brostrom/yolov8_tracking/raw/main/data/videos/people.mp4\"\n",
        "\n",
        "ensure_dir(\"../data/sample_videos\")\n",
        "\n",
        "if not Path(sample_video_path).exists():\n",
        "    print(\"Downloading sample video...\")\n",
        "    success = download_file(sample_video_url, sample_video_path)\n",
        "    if success:\n",
        "        print(\"Sample video downloaded successfully!\")\n",
        "    else:\n",
        "        print(\"Failed to download sample video.\")\n",
        "else:\n",
        "    print(\"Sample video already exists.\")\n",
        "\n",
        "# Check video properties\n",
        "if Path(sample_video_path).exists():\n",
        "    cap = cv2.VideoCapture(sample_video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    duration = frame_count / fps\n",
        "\n",
        "    print(f\"\\nVideo properties:\")\n",
        "    print(f\"Resolution: {width}x{height}\")\n",
        "    print(f\"FPS: {fps}\")\n",
        "    print(f\"Frames: {frame_count}\")\n",
        "    print(f\"Duration: {duration:.2f} seconds\")\n",
        "\n",
        "    cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUNz3MCdHYlx"
      },
      "source": [
        "## 3. YOLO Tracker Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMjlZg8uHYlx"
      },
      "outputs": [],
      "source": [
        "# Initialize YOLO tracker\n",
        "print(\"Initializing YOLO tracker...\")\n",
        "yolo_tracker = YOLOTracker(\n",
        "    model_name='yolov8n.pt',\n",
        "    confidence=0.3,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "print(\"YOLO tracker initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX-aoTF6HYly"
      },
      "outputs": [],
      "source": [
        "# Run YOLO tracking on sample video\n",
        "output_video_yolo = \"../output/sample_tracking_yolo.mp4\"\n",
        "ensure_dir(\"../output\")\n",
        "\n",
        "print(\"Running YOLO tracking...\")\n",
        "yolo_results = yolo_tracker.track_video(\n",
        "    video_path=sample_video_path,\n",
        "    output_path=output_video_yolo\n",
        ")\n",
        "\n",
        "print(f\"YOLO tracking completed! Output saved to: {output_video_yolo}\")\n",
        "print(f\"Processed {len(yolo_results)} frames\")\n",
        "\n",
        "# Display statistics\n",
        "stats = yolo_tracker.get_statistics()\n",
        "print(f\"\\nTracking Statistics:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Avl0rJHYly"
      },
      "source": [
        "## 4. Process Individual Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py77l-ZeHYly"
      },
      "outputs": [],
      "source": [
        "# Process and visualize individual frames\n",
        "cap = cv2.VideoCapture(sample_video_path)\n",
        "yolo_tracker.reset()  # Reset for fresh tracking\n",
        "\n",
        "# Process first few frames and visualize\n",
        "frames_to_show = [10, 30, 50, 70, 90]  # Frame numbers to visualize\n",
        "visualized_frames = []\n",
        "\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run tracking\n",
        "    tracks = yolo_tracker.update(None, frame)\n",
        "\n",
        "    # Save specific frames for visualization\n",
        "    if frame_idx in frames_to_show:\n",
        "        annotated_frame = yolo_tracker.draw_tracks(frame.copy(), tracks)\n",
        "        visualized_frames.append((frame_idx, annotated_frame, len(tracks)))\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "    # Stop early for demo\n",
        "    if frame_idx > max(frames_to_show):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Display frames\n",
        "fig, axes = plt.subplots(1, len(visualized_frames), figsize=(20, 4))\n",
        "if len(visualized_frames) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, (frame_num, frame, track_count) in enumerate(visualized_frames):\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    axes[i].imshow(frame_rgb)\n",
        "    axes[i].set_title(f'Frame {frame_num}\\n{track_count} tracks')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n82qvmsRHYlz"
      },
      "source": [
        "## 5. Compare Detection vs Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUJxMYR_HYlz"
      },
      "outputs": [],
      "source": [
        "# Compare detection-only vs tracking\n",
        "cap = cv2.VideoCapture(sample_video_path)\n",
        "yolo_tracker.reset()\n",
        "\n",
        "# Process one frame to compare\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, 50)  # Go to frame 50\n",
        "ret, frame = cap.read()\n",
        "\n",
        "if ret:\n",
        "    # Detection only\n",
        "    detections = yolo_tracker.detect_only(frame)\n",
        "    frame_detections = frame.copy()\n",
        "\n",
        "    # Draw detections\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2, conf, cls = det\n",
        "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "        cv2.rectangle(frame_detections, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame_detections, f'{conf:.2f}', (x1, y1-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Tracking\n",
        "    tracks = yolo_tracker.update(None, frame)\n",
        "    frame_tracking = yolo_tracker.draw_tracks(frame.copy(), tracks)\n",
        "\n",
        "    # Display comparison\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    ax1.imshow(cv2.cvtColor(frame_detections, cv2.COLOR_BGR2RGB))\n",
        "    ax1.set_title(f'Detection Only\\n{len(detections)} detections')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.imshow(cv2.cvtColor(frame_tracking, cv2.COLOR_BGR2RGB))\n",
        "    ax2.set_title(f'Tracking\\n{len(tracks)} tracks')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSX5SjwGHYlz"
      },
      "source": [
        "## 6. Display Output Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIBkWPXcHYlz"
      },
      "outputs": [],
      "source": [
        "# Display the output video in the notebook\n",
        "if Path(output_video_yolo).exists():\n",
        "    print(\"Original video:\")\n",
        "    display(Video(sample_video_path, width=400))\n",
        "\n",
        "    print(\"\\nTracked video:\")\n",
        "    display(Video(output_video_yolo, width=400))\n",
        "else:\n",
        "    print(\"Output video not found. Please run the tracking cell above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOx_7vC3HYl0"
      },
      "source": [
        "## 7. Track Custom Video (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF7F8qzqHYl0"
      },
      "outputs": [],
      "source": [
        "# Upload and track your own video\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Upload a video file to track:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        # Get the uploaded file\n",
        "        uploaded_filename = list(uploaded.keys())[0]\n",
        "        print(f\"Processing uploaded video: {uploaded_filename}\")\n",
        "\n",
        "        # Track the uploaded video\n",
        "        custom_output = f\"../output/tracked_{uploaded_filename}\"\n",
        "\n",
        "        yolo_tracker.reset()\n",
        "        custom_results = yolo_tracker.track_video(\n",
        "            video_path=uploaded_filename,\n",
        "            output_path=custom_output\n",
        "        )\n",
        "\n",
        "        print(f\"Tracking completed! Output saved to: {custom_output}\")\n",
        "\n",
        "        # Display the result\n",
        "        if Path(custom_output).exists():\n",
        "            display(Video(custom_output, width=600))\n",
        "\n",
        "except ImportError:\n",
        "    print(\"File upload only available in Google Colab.\")\n",
        "    print(\"To track a custom video, place it in the data/sample_videos/ directory and modify the path above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bczrcps2HYl1"
      },
      "source": [
        "## 8. Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jtZzyeBHYl2"
      },
      "outputs": [],
      "source": [
        "# Analyze tracking performance\n",
        "import time\n",
        "\n",
        "def benchmark_tracking(video_path, num_frames=100):\n",
        "    \"\"\"Benchmark tracking performance.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    yolo_tracker.reset()\n",
        "\n",
        "    start_time = time.time()\n",
        "    frame_count = 0\n",
        "    total_tracks = 0\n",
        "\n",
        "    while frame_count < num_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        tracks = yolo_tracker.update(None, frame)\n",
        "        total_tracks += len(tracks)\n",
        "        frame_count += 1\n",
        "\n",
        "    end_time = time.time()\n",
        "    cap.release()\n",
        "\n",
        "    processing_time = end_time - start_time\n",
        "    fps = frame_count / processing_time\n",
        "    avg_tracks = total_tracks / frame_count if frame_count > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'frames_processed': frame_count,\n",
        "        'processing_time': processing_time,\n",
        "        'fps': fps,\n",
        "        'avg_tracks_per_frame': avg_tracks,\n",
        "        'total_tracks': total_tracks\n",
        "    }\n",
        "\n",
        "# Run benchmark\n",
        "print(\"Running performance benchmark...\")\n",
        "benchmark_results = benchmark_tracking(sample_video_path, num_frames=100)\n",
        "\n",
        "print(\"\\n=== Performance Results ===\")\n",
        "for key, value in benchmark_results.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# Check if real-time performance is achieved\n",
        "original_fps = 30  # Assuming 30 FPS original video\n",
        "if benchmark_results['fps'] >= original_fps:\n",
        "    print(f\"\\n✓ Real-time performance achieved! ({benchmark_results['fps']:.1f} FPS > {original_fps} FPS)\")\n",
        "else:\n",
        "    print(f\"\\n⚠ Processing slower than real-time ({benchmark_results['fps']:.1f} FPS < {original_fps} FPS)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv8kkKO8HYl2"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This demo showed:\n",
        "\n",
        "1. **Basic YOLO tracking** on a sample video\n",
        "2. **Frame-by-frame processing** and visualization\n",
        "3. **Detection vs tracking comparison**\n",
        "4. **Performance benchmarking**\n",
        "5. **Custom video processing** capability\n",
        "\n",
        "### Key Features Demonstrated:\n",
        "- ✅ Automatic device detection (CPU/GPU)\n",
        "- ✅ Real-time tracking performance\n",
        "- ✅ Track ID consistency across frames\n",
        "- ✅ Confidence scoring\n",
        "- ✅ Video output generation\n",
        "\n",
        "### Next Steps:\n",
        "- Try `03_soccer_tracking_pipeline.ipynb` for advanced MOT dataset processing\n",
        "- Experiment with different YOLO models (yolov8s, yolov8m, etc.)\n",
        "- Test BotSort tracker for comparison\n",
        "- Evaluate results using `04_evaluation_analysis.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRcaPn3WHYl3"
      },
      "source": [
        "# Soccer Tracking Pipeline\n",
        "\n",
        "This notebook demonstrates the complete soccer tracking pipeline for processing MOT format datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt94v4iGHYl3"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rl8PsCTtHYl3",
        "outputId": "9cc63e52-d0cf-44ad-881e-256fb8888a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src.data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-1094615946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/yolo2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMOTDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLOTracker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBotSortTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMOTEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.data'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import display, Video, HTML\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('/content/yolo2')\n",
        "\n",
        "from src.data import MOTDataLoader\n",
        "from src.tracking import YOLOTracker, BotSortTracker\n",
        "from src.evaluation import MOTEvaluator\n",
        "from src.utils.visualization import plot_tracking_statistics\n",
        "from src.utils.file_utils import ensure_dir\n",
        "from config.paths import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUOhso4EHYl4"
      },
      "source": [
        "## 2. Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO0oXMvCHYl4"
      },
      "outputs": [],
      "source": [
        "# Check if we're in Colab and setup data paths\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab\")\n",
        "\n",
        "    # Use Colab paths\n",
        "    dataset_path = LOCAL_DATASET_PATH\n",
        "    results_dir = LOCAL_RESULTS_DIR\n",
        "\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")\n",
        "\n",
        "    # Use local paths\n",
        "    dataset_path = \"../data/sample_dataset\"\n",
        "    results_dir = \"../output/tracking_results\"\n",
        "\n",
        "print(f\"Dataset path: {dataset_path}\")\n",
        "print(f\"Results directory: {results_dir}\")\n",
        "\n",
        "# Create output directories\n",
        "ensure_dir(results_dir)\n",
        "ensure_dir(\"../output/videos\")\n",
        "ensure_dir(\"../output/plots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rEI6wllHYl4"
      },
      "source": [
        "## 3. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jueLdXG3HYl4"
      },
      "outputs": [],
      "source": [
        "# Load MOT dataset\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"Loading dataset from: {dataset_path}\")\n",
        "    data_loader = MOTDataLoader(dataset_path)\n",
        "\n",
        "    # Get available sequences\n",
        "    sequences = data_loader.get_sequence_list()\n",
        "    print(f\"Found {len(sequences)} sequences: {sequences}\")\n",
        "\n",
        "    # Display dataset information\n",
        "    for seq in sequences[:5]:  # Show first 5 sequences\n",
        "        info = data_loader.get_sequence_info(seq)\n",
        "        print(f\"\\nSequence: {seq}\")\n",
        "        print(f\"  Length: {info['length']} frames\")\n",
        "        print(f\"  Resolution: {info['width']}x{info['height']}\")\n",
        "        print(f\"  FPS: {info['fps']}\")\n",
        "\n",
        "        # Check if detection file exists\n",
        "        detection_file = data_loader.detections_dir / f\"{seq}.txt\"\n",
        "        if detection_file.exists():\n",
        "            detections = data_loader.load_detections(str(detection_file))\n",
        "            total_detections = sum(len(dets) for dets in detections.values())\n",
        "            print(f\"  Detections: {total_detections} total\")\n",
        "        else:\n",
        "            print(f\"  Detections: No detection file found\")\n",
        "\n",
        "else:\n",
        "    print(f\"Dataset not found at: {dataset_path}\")\n",
        "    print(\"Please run the setup notebook first to download/copy the dataset.\")\n",
        "\n",
        "    # Create a dummy dataset for demonstration\n",
        "    print(\"\\nCreating dummy dataset for demonstration...\")\n",
        "    sequences = [\"demo_seq\"]\n",
        "    data_loader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTk9FOyLHYl5"
      },
      "source": [
        "## 4. Tracker Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8jNcIFwHYl5"
      },
      "outputs": [],
      "source": [
        "# Initialize trackers for comparison\n",
        "trackers = {}\n",
        "\n",
        "# YOLO Tracker\n",
        "print(\"Initializing YOLO tracker...\")\n",
        "try:\n",
        "    trackers['YOLO'] = YOLOTracker(\n",
        "        model_name='yolov8n.pt',\n",
        "        confidence=0.3,\n",
        "        device='auto'\n",
        "    )\n",
        "    print(\"✓ YOLO tracker ready\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ YOLO tracker failed: {e}\")\n",
        "\n",
        "# BotSort Tracker\n",
        "print(\"\\nInitializing BotSort tracker...\")\n",
        "try:\n",
        "    trackers['BotSort'] = BotSortTracker(\n",
        "        device='auto' if 'cuda' in str(torch.cuda.is_available()) else 'cpu',\n",
        "        with_reid=False\n",
        "    )\n",
        "    print(\"✓ BotSort tracker ready\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ BotSort tracker failed: {e}\")\n",
        "    print(\"Note: BotSort requires 'boxmot' package. Install with: pip install boxmot\")\n",
        "\n",
        "print(f\"\\nInitialized {len(trackers)} trackers: {list(trackers.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Avrl6x-HYl5"
      },
      "source": [
        "## 5. Process Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQAhn_91HYl6"
      },
      "outputs": [],
      "source": [
        "# Select sequence to process\n",
        "if sequences and data_loader:\n",
        "    test_sequence = sequences[0]  # Use first sequence\n",
        "    print(f\"Processing sequence: {test_sequence}\")\n",
        "\n",
        "    # Load sequence data\n",
        "    detection_file = data_loader.detections_dir / f\"{test_sequence}.txt\"\n",
        "\n",
        "    if detection_file.exists():\n",
        "        detections_by_frame = data_loader.load_detections(str(detection_file))\n",
        "        frames = data_loader.load_sequence_frames(test_sequence)\n",
        "\n",
        "        print(f\"Loaded {len(frames)} frames and {len(detections_by_frame)} detection frames\")\n",
        "\n",
        "        # Process with each tracker\n",
        "        tracking_results = {}\n",
        "\n",
        "        for tracker_name, tracker in trackers.items():\n",
        "            print(f\"\\nProcessing with {tracker_name} tracker...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Reset tracker\n",
        "            tracker.reset()\n",
        "\n",
        "            if tracker_name == 'YOLO':\n",
        "                # YOLO processes frames directly\n",
        "                all_tracks = []\n",
        "                for frame_num, frame_img in frames:\n",
        "                    tracks = tracker.update(None, frame_img)\n",
        "                    all_tracks.append((frame_num, tracks))\n",
        "\n",
        "            elif tracker_name == 'BotSort':\n",
        "                # BotSort uses pre-computed detections\n",
        "                all_tracks = []\n",
        "                for frame_num, frame_img in frames:\n",
        "                    current_detections = detections_by_frame.get(frame_num, [])\n",
        "                    detections_np = np.array(current_detections) if current_detections else np.array([])\n",
        "\n",
        "                    if len(detections_np) > 0:\n",
        "                        tracks = tracker.update(detections_np, frame_img)\n",
        "                    else:\n",
        "                        tracks = np.array([])\n",
        "\n",
        "                    all_tracks.append((frame_num, tracks))\n",
        "\n",
        "            tracking_results[tracker_name] = all_tracks\n",
        "\n",
        "            end_time = time.time()\n",
        "            processing_time = end_time - start_time\n",
        "            fps = len(frames) / processing_time\n",
        "\n",
        "            print(f\"  Processed {len(frames)} frames in {processing_time:.2f}s ({fps:.1f} FPS)\")\n",
        "\n",
        "            # Get tracking statistics\n",
        "            stats = tracker.get_statistics()\n",
        "            print(f\"  Total tracks: {stats['total_tracks']}\")\n",
        "            print(f\"  Avg track length: {stats['avg_track_length']:.1f}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"No detection file found for sequence: {test_sequence}\")\n",
        "\n",
        "else:\n",
        "    print(\"No dataset available for processing.\")\n",
        "    print(\"This is a demonstration of the pipeline structure.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gCMqEz2HYl7"
      },
      "source": [
        "## 6. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vhrQVNCHYl7"
      },
      "outputs": [],
      "source": [
        "# Save tracking results in MOT format\n",
        "if 'tracking_results' in locals() and tracking_results:\n",
        "    for tracker_name, all_tracks in tracking_results.items():\n",
        "        output_file = Path(results_dir) / f\"{test_sequence}_{tracker_name.lower()}.txt\"\n",
        "\n",
        "        print(f\"Saving {tracker_name} results to: {output_file}\")\n",
        "\n",
        "        with open(output_file, 'w') as f:\n",
        "            for frame_num, tracks in all_tracks:\n",
        "                for track in tracks:\n",
        "                    if len(track) >= 7:\n",
        "                        x1, y1, x2, y2, track_id, conf, cls = track[:7]\n",
        "\n",
        "                        # Convert to MOT format\n",
        "                        bb_left = x1\n",
        "                        bb_top = y1\n",
        "                        bb_width = x2 - x1\n",
        "                        bb_height = y2 - y1\n",
        "\n",
        "                        # MOT format: frame,id,bb_left,bb_top,bb_width,bb_height,conf,x,y,z\n",
        "                        line = f\"{frame_num},{int(track_id)},{bb_left:.2f},{bb_top:.2f},{bb_width:.2f},{bb_height:.2f},{conf:.2f},-1,-1,-1\\n\"\n",
        "                        f.write(line)\n",
        "\n",
        "        print(f\"  Saved {len([t for _, tracks in all_tracks for t in tracks])} track entries\")\n",
        "\n",
        "    print(f\"\\nAll results saved to: {results_dir}\")\n",
        "else:\n",
        "    print(\"No tracking results to save.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jop1loIGHYl8"
      },
      "source": [
        "## 7. Generate Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGeSZJ5zHYl8"
      },
      "outputs": [],
      "source": [
        "# Generate tracking videos for visualization\n",
        "if 'tracking_results' in locals() and tracking_results and data_loader:\n",
        "    video_output_dir = \"../output/videos\"\n",
        "    ensure_dir(video_output_dir)\n",
        "\n",
        "    for tracker_name, all_tracks in tracking_results.items():\n",
        "        print(f\"\\nGenerating video for {tracker_name} tracker...\")\n",
        "\n",
        "        # Create annotated frames\n",
        "        annotated_frames = []\n",
        "\n",
        "        # Get frames and add tracking annotations\n",
        "        frames = data_loader.load_sequence_frames(test_sequence)\n",
        "        tracks_dict = {frame_num: tracks for frame_num, tracks in all_tracks}\n",
        "\n",
        "        for frame_num, frame_img in frames:\n",
        "            annotated_frame = frame_img.copy()\n",
        "\n",
        "            # Draw tracks if available\n",
        "            if frame_num in tracks_dict:\n",
        "                tracks = tracks_dict[frame_num]\n",
        "                if len(tracks) > 0:\n",
        "                    # Use the tracker's draw method\n",
        "                    if tracker_name in trackers:\n",
        "                        annotated_frame = trackers[tracker_name].draw_tracks(annotated_frame, tracks)\n",
        "\n",
        "            annotated_frames.append(annotated_frame)\n",
        "\n",
        "        # Save video\n",
        "        if annotated_frames:\n",
        "            from src.utils.visualization import create_video_from_frames\n",
        "\n",
        "            video_path = f\"{video_output_dir}/{test_sequence}_{tracker_name.lower()}_tracking.mp4\"\n",
        "            success = create_video_from_frames(annotated_frames, video_path, fps=30)\n",
        "\n",
        "            if success:\n",
        "                print(f\"  Video saved: {video_path}\")\n",
        "\n",
        "                # Display video in notebook\n",
        "                if os.path.exists(video_path):\n",
        "                    print(f\"  Displaying {tracker_name} tracking video:\")\n",
        "                    display(Video(video_path, width=600))\n",
        "            else:\n",
        "                print(f\"  Failed to create video for {tracker_name}\")\n",
        "\n",
        "else:\n",
        "    print(\"No tracking results available for video generation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtvUk-9YHYl8"
      },
      "source": [
        "## 8. Results Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBQ86AfFHYl9"
      },
      "outputs": [],
      "source": [
        "# Analyze and compare tracking results\n",
        "if 'tracking_results' in locals() and tracking_results:\n",
        "    print(\"=== Tracking Results Analysis ===\")\n",
        "\n",
        "    comparison_data = {}\n",
        "\n",
        "    for tracker_name, all_tracks in tracking_results.items():\n",
        "        # Count total tracks and detections\n",
        "        all_track_ids = set()\n",
        "        total_detections = 0\n",
        "        frame_counts = []\n",
        "\n",
        "        for frame_num, tracks in all_tracks:\n",
        "            frame_counts.append(len(tracks))\n",
        "            total_detections += len(tracks)\n",
        "\n",
        "            for track in tracks:\n",
        "                if len(track) >= 5:\n",
        "                    track_id = int(track[4])\n",
        "                    all_track_ids.add(track_id)\n",
        "\n",
        "        comparison_data[tracker_name] = {\n",
        "            'unique_tracks': len(all_track_ids),\n",
        "            'total_detections': total_detections,\n",
        "            'avg_detections_per_frame': np.mean(frame_counts) if frame_counts else 0,\n",
        "            'max_detections_per_frame': max(frame_counts) if frame_counts else 0,\n",
        "            'frames_processed': len(all_tracks)\n",
        "        }\n",
        "\n",
        "    # Display comparison table\n",
        "    print(\"\\nTracker Comparison:\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Metric':<25} {'YOLO':<15} {'BotSort':<15} {'Difference':<15}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    metrics = ['unique_tracks', 'total_detections', 'avg_detections_per_frame', 'max_detections_per_frame']\n",
        "\n",
        "    for metric in metrics:\n",
        "        yolo_val = comparison_data.get('YOLO', {}).get(metric, 0)\n",
        "        botsort_val = comparison_data.get('BotSort', {}).get(metric, 0)\n",
        "        diff = yolo_val - botsort_val if isinstance(yolo_val, (int, float)) else 'N/A'\n",
        "\n",
        "        print(f\"{metric.replace('_', ' ').title():<25} {yolo_val:<15.1f} {botsort_val:<15.1f} {diff:<15}\")\n",
        "\n",
        "    # Visualize comparison\n",
        "    if len(comparison_data) >= 2:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "        # Plot 1: Unique tracks\n",
        "        trackers_list = list(comparison_data.keys())\n",
        "        unique_tracks = [comparison_data[t]['unique_tracks'] for t in trackers_list]\n",
        "        axes[0, 0].bar(trackers_list, unique_tracks)\n",
        "        axes[0, 0].set_title('Unique Tracks Generated')\n",
        "        axes[0, 0].set_ylabel('Number of Tracks')\n",
        "\n",
        "        # Plot 2: Total detections\n",
        "        total_dets = [comparison_data[t]['total_detections'] for t in trackers_list]\n",
        "        axes[0, 1].bar(trackers_list, total_dets)\n",
        "        axes[0, 1].set_title('Total Detections')\n",
        "        axes[0, 1].set_ylabel('Number of Detections')\n",
        "\n",
        "        # Plot 3: Average detections per frame\n",
        "        avg_dets = [comparison_data[t]['avg_detections_per_frame'] for t in trackers_list]\n",
        "        axes[1, 0].bar(trackers_list, avg_dets)\n",
        "        axes[1, 0].set_title('Average Detections per Frame')\n",
        "        axes[1, 0].set_ylabel('Detections per Frame')\n",
        "\n",
        "        # Plot 4: Max detections per frame\n",
        "        max_dets = [comparison_data[t]['max_detections_per_frame'] for t in trackers_list]\n",
        "        axes[1, 1].bar(trackers_list, max_dets)\n",
        "        axes[1, 1].set_title('Maximum Detections per Frame')\n",
        "        axes[1, 1].set_ylabel('Max Detections')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('../output/plots/tracker_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Comparison plot saved to: ../output/plots/tracker_comparison.png\")\n",
        "\n",
        "else:\n",
        "    print(\"No tracking results available for analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7_gkKX2HYl9"
      },
      "source": [
        "## 9. Command Line Usage Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXBM6zEKHYl-"
      },
      "outputs": [],
      "source": [
        "# Show how to use the command line scripts\n",
        "print(\"=== Command Line Usage Examples ===\")\n",
        "print()\n",
        "print(\"1. Run tracking with BotSort:\")\n",
        "print(f\"   python scripts/run_tracking.py \\\\\")\n",
        "print(f\"       --dataset {dataset_path} \\\\\")\n",
        "print(f\"       --output {results_dir} \\\\\")\n",
        "print(f\"       --tracker botsort \\\\\")\n",
        "print(f\"       --device auto\")\n",
        "print()\n",
        "print(\"2. Run tracking with YOLO:\")\n",
        "print(f\"   python scripts/run_tracking.py \\\\\")\n",
        "print(f\"       --dataset {dataset_path} \\\\\")\n",
        "print(f\"       --output {results_dir} \\\\\")\n",
        "print(f\"       --tracker yolo \\\\\")\n",
        "print(f\"       --confidence 0.3\")\n",
        "print()\n",
        "print(\"3. Evaluate results:\")\n",
        "print(f\"   python scripts/evaluate_results.py \\\\\")\n",
        "print(f\"       --gt_dir {dataset_path}/detections \\\\\")\n",
        "print(f\"       --results_dir {results_dir} \\\\\")\n",
        "print(f\"       --output evaluation_results.json\")\n",
        "print()\n",
        "print(\"4. Download models:\")\n",
        "print(\"   python scripts/download_models.py --all\")\n",
        "print()\n",
        "print(\"These scripts can be run from the command line or terminal.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuTnd9pcHYl-"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Complete soccer tracking pipeline** for MOT datasets\n",
        "2. **Multiple tracker comparison** (YOLO vs BotSort)\n",
        "3. **Automated processing** of entire sequences\n",
        "4. **Results visualization** and analysis\n",
        "5. **Video generation** with tracking annotations\n",
        "6. **Performance benchmarking** and statistics\n",
        "\n",
        "### Key Features:\n",
        "- ✅ MOT format dataset support\n",
        "- ✅ Multiple tracking algorithms\n",
        "- ✅ Automatic hardware detection (CPU/GPU)\n",
        "- ✅ Results export in standard formats\n",
        "- ✅ Comprehensive visualization tools\n",
        "- ✅ Performance analysis and comparison\n",
        "\n",
        "### Next Steps:\n",
        "- Process your own soccer datasets\n",
        "- Experiment with different tracking parameters\n",
        "- Use the evaluation notebook for detailed metric analysis\n",
        "- Scale up to process multiple sequences in batch\n",
        "\n",
        "### For Production Use:\n",
        "- Use the command-line scripts for batch processing\n",
        "- Set up automated pipelines using the provided tools\n",
        "- Monitor performance and optimize parameters\n",
        "- Integrate with your existing workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzyeM5NGHYl-"
      },
      "source": [
        "# Evaluation Analysis\n",
        "\n",
        "This notebook provides comprehensive evaluation and analysis of tracking results using MOT metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d82SopaeHYl_"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X5DVDseHYmA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('..')\n",
        "\n",
        "from src.evaluation import MOTEvaluator\n",
        "from src.evaluation.metrics import calculate_mota, calculate_idf1, calculate_track_quality_metrics\n",
        "from src.utils.visualization import plot_tracking_statistics\n",
        "from src.utils.file_utils import ensure_dir\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o51eK-ncHYmA"
      },
      "source": [
        "## 2. Data Paths Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef3vhQFbHYmB"
      },
      "outputs": [],
      "source": [
        "# Setup evaluation paths\n",
        "gt_dir = \"../data/detections\"  # Ground truth detections\n",
        "results_dir = \"../output/tracking_results\"  # Tracking results\n",
        "plots_dir = \"../output/plots\"\n",
        "eval_output_dir = \"../output/evaluation\"\n",
        "\n",
        "# Create output directories\n",
        "ensure_dir(plots_dir)\n",
        "ensure_dir(eval_output_dir)\n",
        "\n",
        "print(f\"Ground truth directory: {gt_dir}\")\n",
        "print(f\"Results directory: {results_dir}\")\n",
        "print(f\"Plots output: {plots_dir}\")\n",
        "print(f\"Evaluation output: {eval_output_dir}\")\n",
        "\n",
        "# Check available result files\n",
        "if os.path.exists(results_dir):\n",
        "    result_files = list(Path(results_dir).glob(\"*.txt\"))\n",
        "    print(f\"\\nFound {len(result_files)} result files:\")\n",
        "    for f in result_files:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(f\"\\nResults directory not found: {results_dir}\")\n",
        "    print(\"Please run the tracking pipeline first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFlt-PNHHYmB"
      },
      "source": [
        "## 3. Initialize Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKb0yFnVHYmB"
      },
      "outputs": [],
      "source": [
        "# Initialize MOT evaluator\n",
        "evaluator = MOTEvaluator(\n",
        "    metrics=['HOTA', 'CLEAR', 'Identity'],\n",
        "    threshold=0.5\n",
        ")\n",
        "\n",
        "print(\"MOT Evaluator initialized with metrics:\")\n",
        "print(\"  - HOTA: Higher Order Tracking Accuracy\")\n",
        "print(\"  - CLEAR: Classical metrics (MOTA, MOTP)\")\n",
        "print(\"  - Identity: Identity-based metrics (IDF1)\")\n",
        "print(f\"  - IoU threshold: {evaluator.threshold}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyUTqUHHYmC"
      },
      "source": [
        "## 4. Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gf7jcctHYmC"
      },
      "outputs": [],
      "source": [
        "# Run evaluation on available results\n",
        "evaluation_results = {}\n",
        "\n",
        "if os.path.exists(results_dir) and os.path.exists(gt_dir):\n",
        "    # Get list of sequences to evaluate\n",
        "    result_files = list(Path(results_dir).glob(\"*.txt\"))\n",
        "\n",
        "    if result_files:\n",
        "        # Group results by tracker type\n",
        "        tracker_results = {}\n",
        "\n",
        "        for result_file in result_files:\n",
        "            # Parse filename to extract sequence and tracker\n",
        "            filename = result_file.stem\n",
        "\n",
        "            # Try to identify tracker type from filename\n",
        "            if 'yolo' in filename.lower():\n",
        "                tracker_type = 'YOLO'\n",
        "                sequence_name = filename.replace('_yolo', '')\n",
        "            elif 'botsort' in filename.lower():\n",
        "                tracker_type = 'BotSort'\n",
        "                sequence_name = filename.replace('_botsort', '')\n",
        "            else:\n",
        "                tracker_type = 'Unknown'\n",
        "                sequence_name = filename\n",
        "\n",
        "            if tracker_type not in tracker_results:\n",
        "                tracker_results[tracker_type] = []\n",
        "\n",
        "            tracker_results[tracker_type].append(sequence_name)\n",
        "\n",
        "        print(f\"Found tracking results for {len(tracker_results)} tracker types:\")\n",
        "        for tracker, sequences in tracker_results.items():\n",
        "            print(f\"  - {tracker}: {len(sequences)} sequences\")\n",
        "\n",
        "        # Evaluate each tracker\n",
        "        for tracker_type, sequences in tracker_results.items():\n",
        "            print(f\"\\n=== Evaluating {tracker_type} Tracker ===\")\n",
        "\n",
        "            try:\n",
        "                # Create temporary results directory for this tracker\n",
        "                temp_results_dir = Path(eval_output_dir) / f\"temp_{tracker_type.lower()}\"\n",
        "                ensure_dir(str(temp_results_dir))\n",
        "\n",
        "                # Copy results for this tracker\n",
        "                copied_sequences = []\n",
        "                for seq in sequences:\n",
        "                    src_file = Path(results_dir) / f\"{seq}_{tracker_type.lower()}.txt\"\n",
        "                    dst_file = temp_results_dir / f\"{seq}.txt\"\n",
        "\n",
        "                    if src_file.exists():\n",
        "                        import shutil\n",
        "                        shutil.copy2(src_file, dst_file)\n",
        "                        copied_sequences.append(seq)\n",
        "\n",
        "                if copied_sequences:\n",
        "                    # Run evaluation\n",
        "                    metrics = evaluator.evaluate(\n",
        "                        gt_dir=gt_dir,\n",
        "                        results_dir=str(temp_results_dir),\n",
        "                        sequences=copied_sequences\n",
        "                    )\n",
        "\n",
        "                    evaluation_results[tracker_type] = metrics\n",
        "\n",
        "                    # Print results\n",
        "                    evaluator.print_results(metrics)\n",
        "\n",
        "                    # Save results\n",
        "                    results_file = Path(eval_output_dir) / f\"{tracker_type.lower()}_evaluation.json\"\n",
        "                    with open(results_file, 'w') as f:\n",
        "                        json.dump(metrics, f, indent=2)\n",
        "\n",
        "                    print(f\"Results saved to: {results_file}\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"No valid result files found for {tracker_type}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating {tracker_type}: {e}\")\n",
        "                continue\n",
        "\n",
        "    else:\n",
        "        print(\"No result files found for evaluation.\")\n",
        "\n",
        "else:\n",
        "    print(\"Required directories not found for evaluation.\")\n",
        "    print(\"Creating demo evaluation results...\")\n",
        "\n",
        "    # Create demo results for visualization\n",
        "    evaluation_results = {\n",
        "        'YOLO': {\n",
        "            'MOTA': 65.2,\n",
        "            'MOTP': 78.1,\n",
        "            'IDF1': 70.5,\n",
        "            'precision': 85.3,\n",
        "            'recall': 76.8,\n",
        "            'false_positives': 234,\n",
        "            'false_negatives': 456,\n",
        "            'id_switches': 23\n",
        "        },\n",
        "        'BotSort': {\n",
        "            'MOTA': 68.7,\n",
        "            'MOTP': 79.3,\n",
        "            'IDF1': 73.2,\n",
        "            'precision': 87.1,\n",
        "            'recall': 78.9,\n",
        "            'false_positives': 198,\n",
        "            'false_negatives': 423,\n",
        "            'id_switches': 18\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(f\"\\n=== Evaluation Complete ===\")\n",
        "print(f\"Evaluated {len(evaluation_results)} tracker(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkuSLCafHYmD"
      },
      "source": [
        "## 5. Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXWyNgVwHYmD"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive comparison of evaluation metrics\n",
        "if evaluation_results:\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    df_metrics = pd.DataFrame(evaluation_results).T\n",
        "\n",
        "    print(\"=== Metrics Comparison Table ===\")\n",
        "    display(df_metrics.round(2))\n",
        "\n",
        "    # Save comparison table\n",
        "    df_metrics.to_csv(Path(eval_output_dir) / \"metrics_comparison.csv\")\n",
        "    print(f\"\\nComparison table saved to: {eval_output_dir}/metrics_comparison.csv\")\n",
        "\n",
        "    # Create detailed comparison visualizations\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "    # Primary metrics\n",
        "    primary_metrics = ['MOTA', 'MOTP', 'IDF1']\n",
        "    for i, metric in enumerate(primary_metrics):\n",
        "        if metric in df_metrics.columns:\n",
        "            ax = axes[0, i]\n",
        "            df_metrics[metric].plot(kind='bar', ax=ax, color=['skyblue', 'lightcoral'])\n",
        "            ax.set_title(f'{metric} Comparison')\n",
        "            ax.set_ylabel(f'{metric} (%)')\n",
        "            ax.set_xlabel('Tracker')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for j, v in enumerate(df_metrics[metric]):\n",
        "                ax.text(j, v + 1, f'{v:.1f}', ha='center', va='bottom')\n",
        "\n",
        "    # Secondary metrics\n",
        "    secondary_metrics = ['precision', 'recall', 'id_switches']\n",
        "    for i, metric in enumerate(secondary_metrics):\n",
        "        if metric in df_metrics.columns:\n",
        "            ax = axes[1, i]\n",
        "            if metric == 'id_switches':\n",
        "                # Lower is better for ID switches\n",
        "                colors = ['lightgreen' if v == df_metrics[metric].min() else 'lightcoral' for v in df_metrics[metric]]\n",
        "            else:\n",
        "                # Higher is better for precision/recall\n",
        "                colors = ['lightgreen' if v == df_metrics[metric].max() else 'lightcoral' for v in df_metrics[metric]]\n",
        "\n",
        "            df_metrics[metric].plot(kind='bar', ax=ax, color=colors)\n",
        "            ax.set_title(f'{metric.replace(\"_\", \" \").title()} Comparison')\n",
        "            ax.set_ylabel(metric.replace('_', ' ').title())\n",
        "            ax.set_xlabel('Tracker')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for j, v in enumerate(df_metrics[metric]):\n",
        "                if metric == 'id_switches':\n",
        "                    ax.text(j, v + 0.5, f'{int(v)}', ha='center', va='bottom')\n",
        "                else:\n",
        "                    ax.text(j, v + 1, f'{v:.1f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    comparison_plot_path = Path(plots_dir) / \"evaluation_comparison.png\"\n",
        "    plt.savefig(comparison_plot_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Comparison plot saved to: {comparison_plot_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"No evaluation results available for comparison.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhqF_jusHYmD"
      },
      "source": [
        "## 6. Detailed Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C5-3QdMHYmE"
      },
      "outputs": [],
      "source": [
        "# Detailed analysis of tracking performance\n",
        "if evaluation_results:\n",
        "    print(\"=== Detailed Performance Analysis ===\")\n",
        "\n",
        "    for tracker_name, metrics in evaluation_results.items():\n",
        "        print(f\"\\n--- {tracker_name} Tracker Analysis ---\")\n",
        "\n",
        "        # Overall performance assessment\n",
        "        if 'MOTA' in metrics:\n",
        "            mota = metrics['MOTA']\n",
        "            if mota >= 75:\n",
        "                performance = \"Excellent\"\n",
        "            elif mota >= 65:\n",
        "                performance = \"Good\"\n",
        "            elif mota >= 50:\n",
        "                performance = \"Fair\"\n",
        "            else:\n",
        "                performance = \"Poor\"\n",
        "\n",
        "            print(f\"Overall Performance: {performance} (MOTA: {mota:.1f}%)\")\n",
        "\n",
        "        # Detection quality\n",
        "        if 'precision' in metrics and 'recall' in metrics:\n",
        "            precision = metrics['precision']\n",
        "            recall = metrics['recall']\n",
        "            f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "            print(f\"Detection Quality:\")\n",
        "            print(f\"  - Precision: {precision:.1f}% (accuracy of detections)\")\n",
        "            print(f\"  - Recall: {recall:.1f}% (detection completeness)\")\n",
        "            print(f\"  - F1-Score: {f1_score:.1f}% (overall detection quality)\")\n",
        "\n",
        "        # Identity consistency\n",
        "        if 'IDF1' in metrics:\n",
        "            idf1 = metrics['IDF1']\n",
        "            if idf1 >= 70:\n",
        "                id_quality = \"Excellent\"\n",
        "            elif idf1 >= 60:\n",
        "                id_quality = \"Good\"\n",
        "            elif idf1 >= 50:\n",
        "                id_quality = \"Fair\"\n",
        "            else:\n",
        "                id_quality = \"Poor\"\n",
        "\n",
        "            print(f\"Identity Consistency: {id_quality} (IDF1: {idf1:.1f}%)\")\n",
        "\n",
        "        # Error analysis\n",
        "        if 'false_positives' in metrics and 'false_negatives' in metrics:\n",
        "            fp = metrics['false_positives']\n",
        "            fn = metrics['false_negatives']\n",
        "            total_errors = fp + fn\n",
        "\n",
        "            print(f\"Error Analysis:\")\n",
        "            print(f\"  - False Positives: {fp} ({fp/(fp+fn)*100:.1f}% of errors)\")\n",
        "            print(f\"  - False Negatives: {fn} ({fn/(fp+fn)*100:.1f}% of errors)\")\n",
        "            print(f\"  - Total Errors: {total_errors}\")\n",
        "\n",
        "        # ID switches\n",
        "        if 'id_switches' in metrics:\n",
        "            id_sw = metrics['id_switches']\n",
        "            print(f\"Identity Switches: {id_sw} (lower is better)\")\n",
        "\n",
        "    # Best tracker recommendation\n",
        "    if len(evaluation_results) > 1:\n",
        "        print(\"\\n=== Tracker Recommendation ===\")\n",
        "\n",
        "        # Score each tracker based on multiple criteria\n",
        "        tracker_scores = {}\n",
        "\n",
        "        for tracker_name, metrics in evaluation_results.items():\n",
        "            score = 0\n",
        "            criteria_count = 0\n",
        "\n",
        "            # MOTA weight: 30%\n",
        "            if 'MOTA' in metrics:\n",
        "                score += metrics['MOTA'] * 0.3\n",
        "                criteria_count += 30\n",
        "\n",
        "            # IDF1 weight: 25%\n",
        "            if 'IDF1' in metrics:\n",
        "                score += metrics['IDF1'] * 0.25\n",
        "                criteria_count += 25\n",
        "\n",
        "            # Precision weight: 20%\n",
        "            if 'precision' in metrics:\n",
        "                score += metrics['precision'] * 0.2\n",
        "                criteria_count += 20\n",
        "\n",
        "            # Recall weight: 20%\n",
        "            if 'recall' in metrics:\n",
        "                score += metrics['recall'] * 0.2\n",
        "                criteria_count += 20\n",
        "\n",
        "            # ID switches penalty: 5% (lower is better)\n",
        "            if 'id_switches' in metrics:\n",
        "                max_id_switches = max(m.get('id_switches', 0) for m in evaluation_results.values())\n",
        "                if max_id_switches > 0:\n",
        "                    id_switch_score = (1 - metrics['id_switches'] / max_id_switches) * 100\n",
        "                    score += id_switch_score * 0.05\n",
        "                    criteria_count += 5\n",
        "\n",
        "            tracker_scores[tracker_name] = score\n",
        "\n",
        "        # Find best tracker\n",
        "        best_tracker = max(tracker_scores, key=tracker_scores.get)\n",
        "\n",
        "        print(f\"Recommended Tracker: {best_tracker}\")\n",
        "        print(f\"Overall Score: {tracker_scores[best_tracker]:.1f}/100\")\n",
        "\n",
        "        print(\"\\nAll Tracker Scores:\")\n",
        "        for tracker, score in sorted(tracker_scores.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"  {tracker}: {score:.1f}/100\")\n",
        "\n",
        "else:\n",
        "    print(\"No evaluation results available for detailed analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0-0tV6lHYmE"
      },
      "source": [
        "## 7. Radar Chart Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE6ResECHYmF"
      },
      "outputs": [],
      "source": [
        "# Create radar chart for comprehensive comparison\n",
        "if evaluation_results and len(evaluation_results) >= 2:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # Prepare data for radar chart\n",
        "    metrics_to_plot = ['MOTA', 'MOTP', 'IDF1', 'precision', 'recall']\n",
        "    trackers = list(evaluation_results.keys())\n",
        "\n",
        "    # Check which metrics are available\n",
        "    available_metrics = []\n",
        "    for metric in metrics_to_plot:\n",
        "        if all(metric in evaluation_results[tracker] for tracker in trackers):\n",
        "            available_metrics.append(metric)\n",
        "\n",
        "    if len(available_metrics) >= 3:\n",
        "        # Create radar chart\n",
        "        angles = np.linspace(0, 2 * np.pi, len(available_metrics), endpoint=False).tolist()\n",
        "        angles += angles[:1]  # Complete the circle\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "        colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
        "\n",
        "        for i, tracker in enumerate(trackers):\n",
        "            values = []\n",
        "            for metric in available_metrics:\n",
        "                value = evaluation_results[tracker][metric]\n",
        "                # Normalize to 0-100 scale\n",
        "                if metric == 'id_switches':\n",
        "                    # For ID switches, invert and normalize (lower is better)\n",
        "                    max_id_switches = max(evaluation_results[t].get('id_switches', 0) for t in trackers)\n",
        "                    value = (1 - value / max_id_switches) * 100 if max_id_switches > 0 else 100\n",
        "\n",
        "                values.append(value)\n",
        "\n",
        "            values += values[:1]  # Complete the circle\n",
        "\n",
        "            ax.plot(angles, values, 'o-', linewidth=2, label=tracker, color=colors[i % len(colors)])\n",
        "            ax.fill(angles, values, alpha=0.25, color=colors[i % len(colors)])\n",
        "\n",
        "        # Customize the chart\n",
        "        ax.set_xticks(angles[:-1])\n",
        "        ax.set_xticklabels(available_metrics)\n",
        "        ax.set_ylim(0, 100)\n",
        "        ax.set_yticks([20, 40, 60, 80, 100])\n",
        "        ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'])\n",
        "        ax.grid(True)\n",
        "\n",
        "        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "        plt.title('Tracker Performance Comparison\\n(Radar Chart)', size=16, pad=20)\n",
        "\n",
        "        radar_plot_path = Path(plots_dir) / \"tracker_radar_comparison.png\"\n",
        "        plt.savefig(radar_plot_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Radar chart saved to: {radar_plot_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Not enough metrics available for radar chart.\")\n",
        "\n",
        "else:\n",
        "    print(\"Need at least 2 trackers for radar chart comparison.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABtTYiAHYmF"
      },
      "source": [
        "## 8. Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59J3e-RLHYmF"
      },
      "outputs": [],
      "source": [
        "# Export comprehensive evaluation report\n",
        "if evaluation_results:\n",
        "    print(\"=== Exporting Evaluation Report ===\")\n",
        "\n",
        "    # Create comprehensive report\n",
        "    report = {\n",
        "        'evaluation_summary': {\n",
        "            'trackers_evaluated': list(evaluation_results.keys()),\n",
        "            'evaluation_metrics': list(set().union(*(d.keys() for d in evaluation_results.values()))),\n",
        "            'iou_threshold': evaluator.threshold\n",
        "        },\n",
        "        'detailed_results': evaluation_results,\n",
        "        'analysis': {\n",
        "            'best_overall': None,\n",
        "            'best_detection': None,\n",
        "            'best_identity': None,\n",
        "            'recommendations': []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Determine best performers\n",
        "    if len(evaluation_results) > 1:\n",
        "        # Best overall (highest MOTA)\n",
        "        if all('MOTA' in metrics for metrics in evaluation_results.values()):\n",
        "            best_mota = max(evaluation_results, key=lambda x: evaluation_results[x]['MOTA'])\n",
        "            report['analysis']['best_overall'] = best_mota\n",
        "\n",
        "        # Best detection (highest precision)\n",
        "        if all('precision' in metrics for metrics in evaluation_results.values()):\n",
        "            best_detection = max(evaluation_results, key=lambda x: evaluation_results[x]['precision'])\n",
        "            report['analysis']['best_detection'] = best_detection\n",
        "\n",
        "        # Best identity (highest IDF1)\n",
        "        if all('IDF1' in metrics for metrics in evaluation_results.values()):\n",
        "            best_identity = max(evaluation_results, key=lambda x: evaluation_results[x]['IDF1'])\n",
        "            report['analysis']['best_identity'] = best_identity\n",
        "\n",
        "        # Generate recommendations\n",
        "        recommendations = []\n",
        "\n",
        "        for tracker, metrics in evaluation_results.items():\n",
        "            tracker_rec = f\"Use {tracker} for: \"\n",
        "            use_cases = []\n",
        "\n",
        "            if metrics.get('precision', 0) >= 85:\n",
        "                use_cases.append(\"high precision requirements\")\n",
        "\n",
        "            if metrics.get('recall', 0) >= 80:\n",
        "                use_cases.append(\"comprehensive detection\")\n",
        "\n",
        "            if metrics.get('IDF1', 0) >= 70:\n",
        "                use_cases.append(\"identity consistency\")\n",
        "\n",
        "            if metrics.get('id_switches', float('inf')) <= 20:\n",
        "                use_cases.append(\"minimal ID switches\")\n",
        "\n",
        "            if use_cases:\n",
        "                tracker_rec += \", \".join(use_cases)\n",
        "                recommendations.append(tracker_rec)\n",
        "\n",
        "        report['analysis']['recommendations'] = recommendations\n",
        "\n",
        "    # Save comprehensive report\n",
        "    report_file = Path(eval_output_dir) / \"comprehensive_evaluation_report.json\"\n",
        "    with open(report_file, 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "    print(f\"Comprehensive report saved to: {report_file}\")\n",
        "\n",
        "    # Create human-readable summary\n",
        "    summary_file = Path(eval_output_dir) / \"evaluation_summary.txt\"\n",
        "    with open(summary_file, 'w') as f:\n",
        "        f.write(\"SOCCER TRACKING PIPELINE - EVALUATION SUMMARY\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "        f.write(f\"Evaluation Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Trackers Evaluated: {', '.join(evaluation_results.keys())}\\n\")\n",
        "        f.write(f\"IoU Threshold: {evaluator.threshold}\\n\\n\")\n",
        "\n",
        "        # Results table\n",
        "        f.write(\"DETAILED RESULTS\\n\")\n",
        "        f.write(\"-\" * 20 + \"\\n\")\n",
        "\n",
        "        df_metrics = pd.DataFrame(evaluation_results).T\n",
        "        f.write(df_metrics.round(2).to_string())\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        # Analysis\n",
        "        if report['analysis']['best_overall']:\n",
        "            f.write(f\"Best Overall Tracker: {report['analysis']['best_overall']}\\n\")\n",
        "\n",
        "        if report['analysis']['recommendations']:\n",
        "            f.write(\"\\nRECOMMENDATIONS\\n\")\n",
        "            f.write(\"-\" * 15 + \"\\n\")\n",
        "            for rec in report['analysis']['recommendations']:\n",
        "                f.write(f\"• {rec}\\n\")\n",
        "\n",
        "    print(f\"Human-readable summary saved to: {summary_file}\")\n",
        "\n",
        "    # Display final summary\n",
        "    print(\"\\n=== Final Evaluation Summary ===\")\n",
        "    if report['analysis']['best_overall']:\n",
        "        print(f\"🏆 Best Overall Tracker: {report['analysis']['best_overall']}\")\n",
        "\n",
        "    if report['analysis']['recommendations']:\n",
        "        print(\"\\n📋 Key Recommendations:\")\n",
        "        for rec in report['analysis']['recommendations']:\n",
        "            print(f\"   • {rec}\")\n",
        "\n",
        "    print(f\"\\n📁 All results saved to: {eval_output_dir}\")\n",
        "    print(f\"📊 Plots saved to: {plots_dir}\")\n",
        "\n",
        "else:\n",
        "    print(\"No evaluation results to export.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aITaw58xHYmG"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provided comprehensive evaluation and analysis:\n",
        "\n",
        "1. **MOT Metrics Evaluation** using industry-standard protocols\n",
        "2. **Detailed Performance Analysis** for each tracker\n",
        "3. **Visual Comparisons** with charts and plots\n",
        "4. **Tracker Recommendations** based on use cases\n",
        "5. **Comprehensive Reporting** with exportable results\n",
        "\n",
        "### Key Evaluation Metrics:\n",
        "- **MOTA**: Multiple Object Tracking Accuracy (overall performance)\n",
        "- **MOTP**: Multiple Object Tracking Precision (localization accuracy)\n",
        "- **IDF1**: Identity F1 Score (identity consistency)\n",
        "- **Precision/Recall**: Detection quality measures\n",
        "- **ID Switches**: Identity consistency measure\n",
        "\n",
        "### Files Generated:\n",
        "- **Metrics comparison table** (CSV format)\n",
        "- **Visualization plots** (PNG format)\n",
        "- **Comprehensive evaluation report** (JSON format)\n",
        "- **Human-readable summary** (TXT format)\n",
        "\n",
        "### Next Steps:\n",
        "- Use insights to optimize tracking parameters\n",
        "- Compare results across different datasets\n",
        "- Implement tracker selection based on use case\n",
        "- Monitor performance over time with regular evaluations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}