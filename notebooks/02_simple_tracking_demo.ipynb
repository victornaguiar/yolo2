{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Tracking Demo\n",
    "\n",
    "This notebook demonstrates basic object tracking using the soccer tracking pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.tracking import YOLOTracker, BotSortTracker\n",
    "from src.data import VideoGenerator\n",
    "from src.utils.visualization import draw_tracks\n",
    "from src.utils.file_utils import download_file, ensure_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Sample Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have a sample video\n",
    "sample_video_path = \"../data/sample_videos/people.mp4\"\n",
    "sample_video_url = \"https://github.com/mikel-brostrom/yolov8_tracking/raw/main/data/videos/people.mp4\"\n",
    "\n",
    "ensure_dir(\"../data/sample_videos\")\n",
    "\n",
    "if not Path(sample_video_path).exists():\n",
    "    print(\"Downloading sample video...\")\n",
    "    success = download_file(sample_video_url, sample_video_path)\n",
    "    if success:\n",
    "        print(\"Sample video downloaded successfully!\")\n",
    "    else:\n",
    "        print(\"Failed to download sample video.\")\n",
    "else:\n",
    "    print(\"Sample video already exists.\")\n",
    "\n",
    "# Check video properties\n",
    "if Path(sample_video_path).exists():\n",
    "    cap = cv2.VideoCapture(sample_video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    print(f\"\\nVideo properties:\")\n",
    "    print(f\"Resolution: {width}x{height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Frames: {frame_count}\")\n",
    "    print(f\"Duration: {duration:.2f} seconds\")\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLO Tracker Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO tracker\n",
    "print(\"Initializing YOLO tracker...\")\n",
    "yolo_tracker = YOLOTracker(\n",
    "    model_name='yolov8n.pt',\n",
    "    confidence=0.3,\n",
    "    device='auto'\n",
    ")\n",
    "\n",
    "print(\"YOLO tracker initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run YOLO tracking on sample video\n",
    "output_video_yolo = \"../output/sample_tracking_yolo.mp4\"\n",
    "ensure_dir(\"../output\")\n",
    "\n",
    "print(\"Running YOLO tracking...\")\n",
    "yolo_results = yolo_tracker.track_video(\n",
    "    video_path=sample_video_path,\n",
    "    output_path=output_video_yolo\n",
    ")\n",
    "\n",
    "print(f\"YOLO tracking completed! Output saved to: {output_video_yolo}\")\n",
    "print(f\"Processed {len(yolo_results)} frames\")\n",
    "\n",
    "# Display statistics\n",
    "stats = yolo_tracker.get_statistics()\n",
    "print(f\"\\nTracking Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Individual Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and visualize individual frames\n",
    "cap = cv2.VideoCapture(sample_video_path)\n",
    "yolo_tracker.reset()  # Reset for fresh tracking\n",
    "\n",
    "# Process first few frames and visualize\n",
    "frames_to_show = [10, 30, 50, 70, 90]  # Frame numbers to visualize\n",
    "visualized_frames = []\n",
    "\n",
    "frame_idx = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run tracking\n",
    "    tracks = yolo_tracker.update(None, frame)\n",
    "    \n",
    "    # Save specific frames for visualization\n",
    "    if frame_idx in frames_to_show:\n",
    "        annotated_frame = yolo_tracker.draw_tracks(frame.copy(), tracks)\n",
    "        visualized_frames.append((frame_idx, annotated_frame, len(tracks)))\n",
    "    \n",
    "    frame_idx += 1\n",
    "    \n",
    "    # Stop early for demo\n",
    "    if frame_idx > max(frames_to_show):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Display frames\n",
    "fig, axes = plt.subplots(1, len(visualized_frames), figsize=(20, 4))\n",
    "if len(visualized_frames) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (frame_num, frame, track_count) in enumerate(visualized_frames):\n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(frame_rgb)\n",
    "    axes[i].set_title(f'Frame {frame_num}\\n{track_count} tracks')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Detection vs Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare detection-only vs tracking\n",
    "cap = cv2.VideoCapture(sample_video_path)\n",
    "yolo_tracker.reset()\n",
    "\n",
    "# Process one frame to compare\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 50)  # Go to frame 50\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:\n",
    "    # Detection only\n",
    "    detections = yolo_tracker.detect_only(frame)\n",
    "    frame_detections = frame.copy()\n",
    "    \n",
    "    # Draw detections\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2, conf, cls = det\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        cv2.rectangle(frame_detections, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame_detections, f'{conf:.2f}', (x1, y1-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Tracking\n",
    "    tracks = yolo_tracker.update(None, frame)\n",
    "    frame_tracking = yolo_tracker.draw_tracks(frame.copy(), tracks)\n",
    "    \n",
    "    # Display comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    ax1.imshow(cv2.cvtColor(frame_detections, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title(f'Detection Only\\n{len(detections)} detections')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(cv2.cvtColor(frame_tracking, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title(f'Tracking\\n{len(tracks)} tracks')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the output video in the notebook\n",
    "if Path(output_video_yolo).exists():\n",
    "    print(\"Original video:\")\n",
    "    display(Video(sample_video_path, width=400))\n",
    "    \n",
    "    print(\"\\nTracked video:\")\n",
    "    display(Video(output_video_yolo, width=400))\n",
    "else:\n",
    "    print(\"Output video not found. Please run the tracking cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Track Custom Video (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and track your own video\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Upload a video file to track:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        # Get the uploaded file\n",
    "        uploaded_filename = list(uploaded.keys())[0]\n",
    "        print(f\"Processing uploaded video: {uploaded_filename}\")\n",
    "        \n",
    "        # Track the uploaded video\n",
    "        custom_output = f\"../output/tracked_{uploaded_filename}\"\n",
    "        \n",
    "        yolo_tracker.reset()\n",
    "        custom_results = yolo_tracker.track_video(\n",
    "            video_path=uploaded_filename,\n",
    "            output_path=custom_output\n",
    "        )\n",
    "        \n",
    "        print(f\"Tracking completed! Output saved to: {custom_output}\")\n",
    "        \n",
    "        # Display the result\n",
    "        if Path(custom_output).exists():\n",
    "            display(Video(custom_output, width=600))\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"File upload only available in Google Colab.\")\n",
    "    print(\"To track a custom video, place it in the data/sample_videos/ directory and modify the path above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tracking performance\n",
    "import time\n",
    "\n",
    "def benchmark_tracking(video_path, num_frames=100):\n",
    "    \"\"\"Benchmark tracking performance.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    yolo_tracker.reset()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    total_tracks = 0\n",
    "    \n",
    "    while frame_count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        tracks = yolo_tracker.update(None, frame)\n",
    "        total_tracks += len(tracks)\n",
    "        frame_count += 1\n",
    "    \n",
    "    end_time = time.time()\n",
    "    cap.release()\n",
    "    \n",
    "    processing_time = end_time - start_time\n",
    "    fps = frame_count / processing_time\n",
    "    avg_tracks = total_tracks / frame_count if frame_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'frames_processed': frame_count,\n",
    "        'processing_time': processing_time,\n",
    "        'fps': fps,\n",
    "        'avg_tracks_per_frame': avg_tracks,\n",
    "        'total_tracks': total_tracks\n",
    "    }\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Running performance benchmark...\")\n",
    "benchmark_results = benchmark_tracking(sample_video_path, num_frames=100)\n",
    "\n",
    "print(\"\\n=== Performance Results ===\")\n",
    "for key, value in benchmark_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Check if real-time performance is achieved\n",
    "original_fps = 30  # Assuming 30 FPS original video\n",
    "if benchmark_results['fps'] >= original_fps:\n",
    "    print(f\"\\n✓ Real-time performance achieved! ({benchmark_results['fps']:.1f} FPS > {original_fps} FPS)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Processing slower than real-time ({benchmark_results['fps']:.1f} FPS < {original_fps} FPS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showed:\n",
    "\n",
    "1. **Basic YOLO tracking** on a sample video\n",
    "2. **Frame-by-frame processing** and visualization\n",
    "3. **Detection vs tracking comparison**\n",
    "4. **Performance benchmarking**\n",
    "5. **Custom video processing** capability\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "- ✅ Automatic device detection (CPU/GPU)\n",
    "- ✅ Real-time tracking performance\n",
    "- ✅ Track ID consistency across frames\n",
    "- ✅ Confidence scoring\n",
    "- ✅ Video output generation\n",
    "\n",
    "### Next Steps:\n",
    "- Try `03_soccer_tracking_pipeline.ipynb` for advanced MOT dataset processing\n",
    "- Experiment with different YOLO models (yolov8s, yolov8m, etc.)\n",
    "- Test BotSort tracker for comparison\n",
    "- Evaluate results using `04_evaluation_analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}