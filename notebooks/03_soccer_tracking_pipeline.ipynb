{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soccer Tracking Pipeline\n",
    "\n",
    "This notebook demonstrates the complete soccer tracking pipeline for processing MOT format datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, Video, HTML\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data import MOTDataLoader\n",
    "from src.tracking import YOLOTracker, BotSortTracker\n",
    "from src.evaluation import MOTEvaluator\n",
    "from src.utils.visualization import plot_tracking_statistics\n",
    "from src.utils.file_utils import ensure_dir\n",
    "from config.paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Colab and setup data paths\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "    \n",
    "    # Use Colab paths\n",
    "    dataset_path = LOCAL_DATASET_PATH\n",
    "    results_dir = LOCAL_RESULTS_DIR\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "    \n",
    "    # Use local paths\n",
    "    dataset_path = \"../data/sample_dataset\"\n",
    "    results_dir = \"../output/tracking_results\"\n",
    "\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "\n",
    "# Create output directories\n",
    "ensure_dir(results_dir)\n",
    "ensure_dir(\"../output/videos\")\n",
    "ensure_dir(\"../output/plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MOT dataset\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Loading dataset from: {dataset_path}\")\n",
    "    data_loader = MOTDataLoader(dataset_path)\n",
    "    \n",
    "    # Get available sequences\n",
    "    sequences = data_loader.get_sequence_list()\n",
    "    print(f\"Found {len(sequences)} sequences: {sequences}\")\n",
    "    \n",
    "    # Display dataset information\n",
    "    for seq in sequences[:5]:  # Show first 5 sequences\n",
    "        info = data_loader.get_sequence_info(seq)\n",
    "        print(f\"\\nSequence: {seq}\")\n",
    "        print(f\"  Length: {info['length']} frames\")\n",
    "        print(f\"  Resolution: {info['width']}x{info['height']}\")\n",
    "        print(f\"  FPS: {info['fps']}\")\n",
    "        \n",
    "        # Check if detection file exists\n",
    "        detection_file = data_loader.detections_dir / f\"{seq}.txt\"\n",
    "        if detection_file.exists():\n",
    "            detections = data_loader.load_detections(str(detection_file))\n",
    "            total_detections = sum(len(dets) for dets in detections.values())\n",
    "            print(f\"  Detections: {total_detections} total\")\n",
    "        else:\n",
    "            print(f\"  Detections: No detection file found\")\n",
    "            \n",
    "else:\n",
    "    print(f\"Dataset not found at: {dataset_path}\")\n",
    "    print(\"Please run the setup notebook first to download/copy the dataset.\")\n",
    "    \n",
    "    # Create a dummy dataset for demonstration\n",
    "    print(\"\\nCreating dummy dataset for demonstration...\")\n",
    "    sequences = [\"demo_seq\"]\n",
    "    data_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tracker Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trackers for comparison\n",
    "trackers = {}\n",
    "\n",
    "# YOLO Tracker\n",
    "print(\"Initializing YOLO tracker...\")\n",
    "try:\n",
    "    trackers['YOLO'] = YOLOTracker(\n",
    "        model_name='yolov8n.pt',\n",
    "        confidence=0.3,\n",
    "        device='auto'\n",
    "    )\n",
    "    print(\"✓ YOLO tracker ready\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ YOLO tracker failed: {e}\")\n",
    "\n",
    "# BotSort Tracker\n",
    "print(\"\\nInitializing BotSort tracker...\")\n",
    "try:\n",
    "    trackers['BotSort'] = BotSortTracker(\n",
    "        device='auto' if 'cuda' in str(torch.cuda.is_available()) else 'cpu',\n",
    "        with_reid=False\n",
    "    )\n",
    "    print(\"✓ BotSort tracker ready\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ BotSort tracker failed: {e}\")\n",
    "    print(\"Note: BotSort requires 'boxmot' package. Install with: pip install boxmot\")\n",
    "\n",
    "print(f\"\\nInitialized {len(trackers)} trackers: {list(trackers.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sequence to process\n",
    "if sequences and data_loader:\n",
    "    test_sequence = sequences[0]  # Use first sequence\n",
    "    print(f\"Processing sequence: {test_sequence}\")\n",
    "    \n",
    "    # Load sequence data\n",
    "    detection_file = data_loader.detections_dir / f\"{test_sequence}.txt\"\n",
    "    \n",
    "    if detection_file.exists():\n",
    "        detections_by_frame = data_loader.load_detections(str(detection_file))\n",
    "        frames = data_loader.load_sequence_frames(test_sequence)\n",
    "        \n",
    "        print(f\"Loaded {len(frames)} frames and {len(detections_by_frame)} detection frames\")\n",
    "        \n",
    "        # Process with each tracker\n",
    "        tracking_results = {}\n",
    "        \n",
    "        for tracker_name, tracker in trackers.items():\n",
    "            print(f\"\\nProcessing with {tracker_name} tracker...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Reset tracker\n",
    "            tracker.reset()\n",
    "            \n",
    "            if tracker_name == 'YOLO':\n",
    "                # YOLO processes frames directly\n",
    "                all_tracks = []\n",
    "                for frame_num, frame_img in frames:\n",
    "                    tracks = tracker.update(None, frame_img)\n",
    "                    all_tracks.append((frame_num, tracks))\n",
    "                    \n",
    "            elif tracker_name == 'BotSort':\n",
    "                # BotSort uses pre-computed detections\n",
    "                all_tracks = []\n",
    "                for frame_num, frame_img in frames:\n",
    "                    current_detections = detections_by_frame.get(frame_num, [])\n",
    "                    detections_np = np.array(current_detections) if current_detections else np.array([])\n",
    "                    \n",
    "                    if len(detections_np) > 0:\n",
    "                        tracks = tracker.update(detections_np, frame_img)\n",
    "                    else:\n",
    "                        tracks = np.array([])\n",
    "                    \n",
    "                    all_tracks.append((frame_num, tracks))\n",
    "            \n",
    "            tracking_results[tracker_name] = all_tracks\n",
    "            \n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            fps = len(frames) / processing_time\n",
    "            \n",
    "            print(f\"  Processed {len(frames)} frames in {processing_time:.2f}s ({fps:.1f} FPS)\")\n",
    "            \n",
    "            # Get tracking statistics\n",
    "            stats = tracker.get_statistics()\n",
    "            print(f\"  Total tracks: {stats['total_tracks']}\")\n",
    "            print(f\"  Avg track length: {stats['avg_track_length']:.1f}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"No detection file found for sequence: {test_sequence}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No dataset available for processing.\")\n",
    "    print(\"This is a demonstration of the pipeline structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tracking results in MOT format\n",
    "if 'tracking_results' in locals() and tracking_results:\n",
    "    for tracker_name, all_tracks in tracking_results.items():\n",
    "        output_file = Path(results_dir) / f\"{test_sequence}_{tracker_name.lower()}.txt\"\n",
    "        \n",
    "        print(f\"Saving {tracker_name} results to: {output_file}\")\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            for frame_num, tracks in all_tracks:\n",
    "                for track in tracks:\n",
    "                    if len(track) >= 7:\n",
    "                        x1, y1, x2, y2, track_id, conf, cls = track[:7]\n",
    "                        \n",
    "                        # Convert to MOT format\n",
    "                        bb_left = x1\n",
    "                        bb_top = y1\n",
    "                        bb_width = x2 - x1\n",
    "                        bb_height = y2 - y1\n",
    "                        \n",
    "                        # MOT format: frame,id,bb_left,bb_top,bb_width,bb_height,conf,x,y,z\n",
    "                        line = f\"{frame_num},{int(track_id)},{bb_left:.2f},{bb_top:.2f},{bb_width:.2f},{bb_height:.2f},{conf:.2f},-1,-1,-1\\n\"\n",
    "                        f.write(line)\n",
    "        \n",
    "        print(f\"  Saved {len([t for _, tracks in all_tracks for t in tracks])} track entries\")\n",
    "\n",
    "    print(f\"\\nAll results saved to: {results_dir}\")\n",
    "else:\n",
    "    print(\"No tracking results to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tracking videos for visualization\n",
    "if 'tracking_results' in locals() and tracking_results and data_loader:\n",
    "    video_output_dir = \"../output/videos\"\n",
    "    ensure_dir(video_output_dir)\n",
    "    \n",
    "    for tracker_name, all_tracks in tracking_results.items():\n",
    "        print(f\"\\nGenerating video for {tracker_name} tracker...\")\n",
    "        \n",
    "        # Create annotated frames\n",
    "        annotated_frames = []\n",
    "        \n",
    "        # Get frames and add tracking annotations\n",
    "        frames = data_loader.load_sequence_frames(test_sequence)\n",
    "        tracks_dict = {frame_num: tracks for frame_num, tracks in all_tracks}\n",
    "        \n",
    "        for frame_num, frame_img in frames:\n",
    "            annotated_frame = frame_img.copy()\n",
    "            \n",
    "            # Draw tracks if available\n",
    "            if frame_num in tracks_dict:\n",
    "                tracks = tracks_dict[frame_num]\n",
    "                if len(tracks) > 0:\n",
    "                    # Use the tracker's draw method\n",
    "                    if tracker_name in trackers:\n",
    "                        annotated_frame = trackers[tracker_name].draw_tracks(annotated_frame, tracks)\n",
    "            \n",
    "            annotated_frames.append(annotated_frame)\n",
    "        \n",
    "        # Save video\n",
    "        if annotated_frames:\n",
    "            from src.utils.visualization import create_video_from_frames\n",
    "            \n",
    "            video_path = f\"{video_output_dir}/{test_sequence}_{tracker_name.lower()}_tracking.mp4\"\n",
    "            success = create_video_from_frames(annotated_frames, video_path, fps=30)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"  Video saved: {video_path}\")\n",
    "                \n",
    "                # Display video in notebook\n",
    "                if os.path.exists(video_path):\n",
    "                    print(f\"  Displaying {tracker_name} tracking video:\")\n",
    "                    display(Video(video_path, width=600))\n",
    "            else:\n",
    "                print(f\"  Failed to create video for {tracker_name}\")\n",
    "                \n",
    "else:\n",
    "    print(\"No tracking results available for video generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and compare tracking results\n",
    "if 'tracking_results' in locals() and tracking_results:\n",
    "    print(\"=== Tracking Results Analysis ===\")\n",
    "    \n",
    "    comparison_data = {}\n",
    "    \n",
    "    for tracker_name, all_tracks in tracking_results.items():\n",
    "        # Count total tracks and detections\n",
    "        all_track_ids = set()\n",
    "        total_detections = 0\n",
    "        frame_counts = []\n",
    "        \n",
    "        for frame_num, tracks in all_tracks:\n",
    "            frame_counts.append(len(tracks))\n",
    "            total_detections += len(tracks)\n",
    "            \n",
    "            for track in tracks:\n",
    "                if len(track) >= 5:\n",
    "                    track_id = int(track[4])\n",
    "                    all_track_ids.add(track_id)\n",
    "        \n",
    "        comparison_data[tracker_name] = {\n",
    "            'unique_tracks': len(all_track_ids),\n",
    "            'total_detections': total_detections,\n",
    "            'avg_detections_per_frame': np.mean(frame_counts) if frame_counts else 0,\n",
    "            'max_detections_per_frame': max(frame_counts) if frame_counts else 0,\n",
    "            'frames_processed': len(all_tracks)\n",
    "        }\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(\"\\nTracker Comparison:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Metric':<25} {'YOLO':<15} {'BotSort':<15} {'Difference':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    metrics = ['unique_tracks', 'total_detections', 'avg_detections_per_frame', 'max_detections_per_frame']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        yolo_val = comparison_data.get('YOLO', {}).get(metric, 0)\n",
    "        botsort_val = comparison_data.get('BotSort', {}).get(metric, 0)\n",
    "        diff = yolo_val - botsort_val if isinstance(yolo_val, (int, float)) else 'N/A'\n",
    "        \n",
    "        print(f\"{metric.replace('_', ' ').title():<25} {yolo_val:<15.1f} {botsort_val:<15.1f} {diff:<15}\")\n",
    "    \n",
    "    # Visualize comparison\n",
    "    if len(comparison_data) >= 2:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        # Plot 1: Unique tracks\n",
    "        trackers_list = list(comparison_data.keys())\n",
    "        unique_tracks = [comparison_data[t]['unique_tracks'] for t in trackers_list]\n",
    "        axes[0, 0].bar(trackers_list, unique_tracks)\n",
    "        axes[0, 0].set_title('Unique Tracks Generated')\n",
    "        axes[0, 0].set_ylabel('Number of Tracks')\n",
    "        \n",
    "        # Plot 2: Total detections\n",
    "        total_dets = [comparison_data[t]['total_detections'] for t in trackers_list]\n",
    "        axes[0, 1].bar(trackers_list, total_dets)\n",
    "        axes[0, 1].set_title('Total Detections')\n",
    "        axes[0, 1].set_ylabel('Number of Detections')\n",
    "        \n",
    "        # Plot 3: Average detections per frame\n",
    "        avg_dets = [comparison_data[t]['avg_detections_per_frame'] for t in trackers_list]\n",
    "        axes[1, 0].bar(trackers_list, avg_dets)\n",
    "        axes[1, 0].set_title('Average Detections per Frame')\n",
    "        axes[1, 0].set_ylabel('Detections per Frame')\n",
    "        \n",
    "        # Plot 4: Max detections per frame\n",
    "        max_dets = [comparison_data[t]['max_detections_per_frame'] for t in trackers_list]\n",
    "        axes[1, 1].bar(trackers_list, max_dets)\n",
    "        axes[1, 1].set_title('Maximum Detections per Frame')\n",
    "        axes[1, 1].set_ylabel('Max Detections')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../output/plots/tracker_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Comparison plot saved to: ../output/plots/tracker_comparison.png\")\n",
    "\n",
    "else:\n",
    "    print(\"No tracking results available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Command Line Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how to use the command line scripts\n",
    "print(\"=== Command Line Usage Examples ===\")\n",
    "print()\n",
    "print(\"1. Run tracking with BotSort:\")\n",
    "print(f\"   python scripts/run_tracking.py \\\\\")\n",
    "print(f\"       --dataset {dataset_path} \\\\\")\n",
    "print(f\"       --output {results_dir} \\\\\")\n",
    "print(f\"       --tracker botsort \\\\\")\n",
    "print(f\"       --device auto\")\n",
    "print()\n",
    "print(\"2. Run tracking with YOLO:\")\n",
    "print(f\"   python scripts/run_tracking.py \\\\\")\n",
    "print(f\"       --dataset {dataset_path} \\\\\")\n",
    "print(f\"       --output {results_dir} \\\\\")\n",
    "print(f\"       --tracker yolo \\\\\")\n",
    "print(f\"       --confidence 0.3\")\n",
    "print()\n",
    "print(\"3. Evaluate results:\")\n",
    "print(f\"   python scripts/evaluate_results.py \\\\\")\n",
    "print(f\"       --gt_dir {dataset_path}/detections \\\\\")\n",
    "print(f\"       --results_dir {results_dir} \\\\\")\n",
    "print(f\"       --output evaluation_results.json\")\n",
    "print()\n",
    "print(\"4. Download models:\")\n",
    "print(\"   python scripts/download_models.py --all\")\n",
    "print()\n",
    "print(\"These scripts can be run from the command line or terminal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Complete soccer tracking pipeline** for MOT datasets\n",
    "2. **Multiple tracker comparison** (YOLO vs BotSort)\n",
    "3. **Automated processing** of entire sequences\n",
    "4. **Results visualization** and analysis\n",
    "5. **Video generation** with tracking annotations\n",
    "6. **Performance benchmarking** and statistics\n",
    "\n",
    "### Key Features:\n",
    "- ✅ MOT format dataset support\n",
    "- ✅ Multiple tracking algorithms\n",
    "- ✅ Automatic hardware detection (CPU/GPU)\n",
    "- ✅ Results export in standard formats\n",
    "- ✅ Comprehensive visualization tools\n",
    "- ✅ Performance analysis and comparison\n",
    "\n",
    "### Next Steps:\n",
    "- Process your own soccer datasets\n",
    "- Experiment with different tracking parameters\n",
    "- Use the evaluation notebook for detailed metric analysis\n",
    "- Scale up to process multiple sequences in batch\n",
    "\n",
    "### For Production Use:\n",
    "- Use the command-line scripts for batch processing\n",
    "- Set up automated pipelines using the provided tools\n",
    "- Monitor performance and optimize parameters\n",
    "- Integrate with your existing workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}