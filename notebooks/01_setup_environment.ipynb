{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup for Soccer Tracking Pipeline\n",
    "\n",
    "This notebook helps you set up the environment for running the soccer tracking pipeline on Google Colab with remote VM access via VS Code SSH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA support (automatically detects available CUDA version)\n",
    "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install computer vision and tracking libraries\n",
    "!pip install ultralytics boxmot opencv-python numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install evaluation library\n",
    "!pip install -q git+https://github.com/JonathonLuiten/TrackEval.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional utilities\n",
    "!pip install tqdm matplotlib pandas pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive (for data access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for dataset access\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted successfully!\")\n",
    "    \n",
    "    # Check if soccer data exists\n",
    "    import os\n",
    "    gdrive_path = \"/content/drive/MyDrive/SOCCER_DATA\"\n",
    "    if os.path.exists(gdrive_path):\n",
    "        print(f\"Soccer data found at: {gdrive_path}\")\n",
    "        print(\"Available datasets:\")\n",
    "        for item in os.listdir(gdrive_path):\n",
    "            print(f\"  - {item}\")\n",
    "    else:\n",
    "        print(f\"No soccer data found at: {gdrive_path}\")\n",
    "        print(\"Please upload your dataset to Google Drive first.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab. Skipping drive mount.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error mounting drive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository if not already present\n",
    "import os\n",
    "\n",
    "if not os.path.exists('/content/soccer-tracking-pipeline'):\n",
    "    !git clone https://github.com/yourusername/soccer-tracking-pipeline.git\n",
    "    \n",
    "%cd /content/soccer-tracking-pipeline\n",
    "\n",
    "# Install project dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Installation and Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hardware and installations\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"=== Hardware Information ===\")\n",
    "print(f\"Python version: {torch.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "        print(f\"  GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "\n",
    "print(f\"\\n=== Library Versions ===\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Test YOLO\n",
    "try:\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    print(f\"YOLO model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO: {e}\")\n",
    "\n",
    "# Test BotSort\n",
    "try:\n",
    "    from boxmot import BotSORT\n",
    "    print(f\"BotSORT available\")\n",
    "except ImportError:\n",
    "    print(f\"BotSORT not available - install with: pip install boxmot\")\n",
    "\n",
    "print(\"\\n✓ All core libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Sample Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample data and models\n",
    "!python scripts/download_models.py --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set Up SSH for Remote Development (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and configure SSH for VS Code remote development\n",
    "!pip install colab-ssh -q\n",
    "\n",
    "print(\"SSH setup ready. To connect VS Code remotely, run:\")\n",
    "print(\"\")\n",
    "print(\"from colab_ssh import launch_ssh_cloudflared\")\n",
    "print(\"launch_ssh_cloudflared(password='your_secure_password')\")\n",
    "print(\"\")\n",
    "print(\"Then follow the instructions to connect VS Code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to start SSH server\n",
    "# from colab_ssh import launch_ssh_cloudflared\n",
    "# launch_ssh_cloudflared(password=\"your_secure_password_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Copy Dataset from Google Drive to Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset from Google Drive to local SSD for faster access\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "gdrive_dataset = \"/content/drive/MyDrive/SOCCER_DATA/deepsort_dataset_train\"\n",
    "local_dataset = \"/content/soccer_dataset\"\n",
    "\n",
    "if os.path.exists(gdrive_dataset):\n",
    "    print(f\"Copying dataset from Google Drive to local SSD...\")\n",
    "    print(f\"Source: {gdrive_dataset}\")\n",
    "    print(f\"Destination: {local_dataset}\")\n",
    "    \n",
    "    if os.path.exists(local_dataset):\n",
    "        print(\"Local dataset already exists. Skipping copy.\")\n",
    "    else:\n",
    "        shutil.copytree(gdrive_dataset, local_dataset)\n",
    "        print(\"Dataset copied successfully!\")\n",
    "    \n",
    "    # Verify dataset structure\n",
    "    print(\"\\nDataset structure:\")\n",
    "    for root, dirs, files in os.walk(local_dataset):\n",
    "        level = root.replace(local_dataset, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Show first 5 files only\n",
    "            print(f\"{subindent}{file}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{subindent}... and {len(files) - 5} more files\")\n",
    "else:\n",
    "    print(f\"Dataset not found at: {gdrive_dataset}\")\n",
    "    print(\"Please upload your dataset to Google Drive first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the tracking pipeline\n",
    "from src.tracking import YOLOTracker\n",
    "from src.data import VideoGenerator\n",
    "import cv2\n",
    "\n",
    "# Test with sample video\n",
    "sample_video = \"data/sample_videos/people.mp4\"\n",
    "\n",
    "if os.path.exists(sample_video):\n",
    "    print(\"Testing YOLO tracker on sample video...\")\n",
    "    \n",
    "    # Initialize tracker\n",
    "    tracker = YOLOTracker(device='auto')\n",
    "    \n",
    "    # Process a few frames\n",
    "    cap = cv2.VideoCapture(sample_video)\n",
    "    frame_count = 0\n",
    "    \n",
    "    while frame_count < 10:  # Process first 10 frames\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        tracks = tracker.update(None, frame)\n",
    "        print(f\"Frame {frame_count}: {len(tracks)} tracks detected\")\n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"✓ Pipeline test completed successfully!\")\n",
    "else:\n",
    "    print(f\"Sample video not found at: {sample_video}\")\n",
    "    print(\"Run the download script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Your environment is now set up! You can:\n",
    "\n",
    "1. **Run the simple tracking demo**: Open `02_simple_tracking_demo.ipynb`\n",
    "2. **Process soccer datasets**: Open `03_soccer_tracking_pipeline.ipynb`\n",
    "3. **Evaluate results**: Open `04_evaluation_analysis.ipynb`\n",
    "4. **Use command-line scripts**:\n",
    "   - Track videos: `python scripts/run_tracking.py --help`\n",
    "   - Evaluate results: `python scripts/evaluate_results.py --help`\n",
    "\n",
    "### For Remote Development:\n",
    "- Connect VS Code using the SSH tunnel created above\n",
    "- Access files on the VM's SSD for fast processing\n",
    "- Leverage GPU acceleration automatically\n",
    "\n",
    "### Performance Tips:\n",
    "- Use the local SSD (`/content/`) for active datasets\n",
    "- Keep original data on Google Drive for backup\n",
    "- Monitor GPU memory usage with `nvidia-smi`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}