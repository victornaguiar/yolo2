{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Complete Project Setup (Run This Cell Only Once Per Session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import drive\n",
    "\n",
    "# --- 1. Define Key Paths ---\n",
    "drive_mount_point = '/content/drive'\n",
    "master_data_dir_on_drive = os.path.join(drive_mount_point, 'My Drive/colab_data/yolo2_data')\n",
    "master_video_path_on_drive = os.path.join(master_data_dir_on_drive, 'soccer.mp4')\n",
    "local_data_dir = '/content/data'\n",
    "local_video_path = os.path.join(local_data_dir, 'soccer.mp4')\n",
    "\n",
    "# --- 2. Mount Google Drive ---\n",
    "print(\"Mounting Google Drive...\")\n",
    "drive.mount(drive_mount_point, force_remount=True)\n",
    "\n",
    "# --- 3. High-Speed Data Sync Logic ---\n",
    "print(\"\\nSyncing data for high-speed access...\")\n",
    "os.makedirs(local_data_dir, exist_ok=True)\n",
    "if not os.path.exists(local_video_path):\n",
    "    print(\"Local data not found. Checking Google Drive...\")\n",
    "    \n",
    "    if not os.path.exists(master_video_path_on_drive):\n",
    "        print(\"Data not found on Drive. Performing ONE-TIME download from internet...\")\n",
    "        os.makedirs(master_data_dir_on_drive, exist_ok=True)\n",
    "        # The gdown command to download your specific data to your Drive\n",
    "        !gdown --id 1-2S26402YUn_S2aG_2S1i-tWbW0QASgB -O '{master_video_path_on_drive}'\n",
    "        print(\"✓ Dataset downloaded to Google Drive.\")\n",
    "    else:\n",
    "        print(\"✓ Data found on Google Drive.\")\n",
    "\n",
    "    # The key step: Copy from slow Drive to fast local SSD\n",
    "    print(\"Copying data from Google Drive to local VM for high-speed access...\")\n",
    "    !cp '{master_video_path_on_drive}' '{local_video_path}'\n",
    "    print(\"✓ Data is now on the local SSD.\")\n",
    "else:\n",
    "    print(\"✓ High-speed local data already exists on the VM.\")\n",
    "\n",
    "# --- 4. GitHub Repo and Environment Setup ---\n",
    "print(\"\\nSetting up project repository and dependencies...\")\n",
    "if not os.path.exists('/content/yolo2'):\n",
    "    !git clone https://github.com/victornaguiar/yolo2.git /content/yolo2\n",
    "else:\n",
    "    print(\"Repository already exists.\")\n",
    "\n",
    "project_dir = '/content/yolo2'\n",
    "%cd {project_dir}\n",
    "\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.insert(0, project_dir)\n",
    "\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q boxmot\n",
    "\n",
    "# --- 5. Link the Local Data to the Project ---\n",
    "project_data_dir = os.path.join(project_dir, 'data')\n",
    "os.makedirs(project_data_dir, exist_ok=True)\n",
    "linked_video_path = os.path.join(project_data_dir, 'soccer.mp4')\n",
    "\n",
    "if os.path.lexists(linked_video_path):\n",
    "    os.remove(linked_video_path)\n",
    "\n",
    "# Create the symlink to the FAST, LOCAL copy of the data\n",
    "os.symlink(local_video_path, linked_video_path)\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\n======================================================================\")\n",
    "print(\"✓✓✓ ENVIRONMENT IS FULLY PREPARED FOR HIGH-PERFORMANCE RUN ✓✓✓\")\n",
    "print(\"======================================================================\")\n",
    "print(f\"Model will read data from (fast local SSD): {os.path.realpath(linked_video_path)}\")\n",
    "!ls -l {project_data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Simple Tracking Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "from boxmot import DeepOCSORT\n",
    "from boxmot.utils import ROOT, WEIGHTS\n",
    "from boxmot.tracker_zoo import create_tracker\n",
    "from boxmot.utils.checks import TestRequirements\n",
    "from boxmot.utils.torch_utils import select_device\n",
    "from boxmot.utils.plotting import Colors, Annotator\n",
    "from boxmot.yolo.utils.files import increment_path\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "yolo_model = Path('yolov8n.pt')\n",
    "tracking_method = 'deepocsort' # deepocsort, botsort, strongsort, ocsort, bytetrack\n",
    "reid_model = Path('osnet_x0_25_msmt17.pt')\n",
    "source = Path('data/people_walking.mp4')\n",
    "device = 'cpu' # 'cuda:0', 'cuda:1', ..\n",
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Create instances"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances\n",
    "model = YOLO(yolo_model)\n",
    "\n",
    "tracker = create_tracker(\n",
    "    tracker_type=tracking_method,\n",
    "    model_weights=reid_model, # which ReID model to use\n",
    "    device=device, # 'cpu', 'cuda:0', 'cuda:1', ...\n",
    "    fp16=False, # wether to run the ReID model with fp16\n",
    "    #asso_func=\"ciou\",  # 'iou' or 'ciou'\n",
    "    #delta_t=3, # time step\n",
    "    #asso_thresh=0.2, # iou threshold\n",
    "    #min_hits=3, # minimum hits to create a track\n",
    "    #inertia=0.2, # inertia factor\n",
    "    #use_byte=True # wether to use byte track\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Run detection and tracking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection and tracking\n",
    "results = model.track(\n",
    "    source=str(source),\n",
    "    tracker=tracking_method, # here you can choose the tracker type\n",
    "    persist=True,\n",
    "    conf=0.3,\n",
    "    iou=0.5,\n",
    "    classes=0, # track people only\n",
    "    verbose=False,\n",
    "    #tracker='cfg/trackers/deepocsort.yaml' # you can also specify your own tracker config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Process results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results\n",
    "for frame in results:\n",
    "    # you can print the frame object to see what it contains\n",
    "    # print(frame)\n",
    "    # you can also see the frame image\n",
    "    # frame.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3: Soccer Tracking Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "from boxmot import DeepOCSORT\n",
    "from boxmot.utils import ROOT, WEIGHTS\n",
    "from boxmot.tracker_zoo import create_tracker\n",
    "from boxmot.utils.checks import TestRequirements\n",
    "from boxmot.utils.torch_utils import select_device\n",
    "from boxmot.utils.plotting import Colors, Annotator\n",
    "from boxmot.yolo.utils.files import increment_path"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Utils"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file was opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return None\n",
    "\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Create a dictionary to store video information\n",
    "    video_info = {\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'fps': fps,\n",
    "        'frame_count': frame_count\n",
    "    }\n",
    "\n",
    "    return video_info\n",
    "\n",
    "def create_video_writer(video_info, output_path, fourcc='mp4v'):\n",
    "    # Create a VideoWriter object to save the output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*fourcc) # You can also use 'XVID' for .avi format\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, video_info['fps'], (video_info['width'], video_info['height']))\n",
    "\n",
    "    return video_writer\n",
    "\n",
    "def ensure_dir(path):\n",
    "    # Create the directory if it does not exist\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "yolo_model = Path('../models/yolov8n.pt')\n",
    "source = Path('../data/soccer.mp4')\n",
    "device = 'cuda:0' # 'cpu', 'cuda:0', 'cuda:1', ..\n",
    "project = '../output'\n",
    "name = 'exp'\n",
    "save = True\n",
    "show = False\n",
    "# tracking parameters\n",
    "conf = 0.5\n",
    "iou = 0.7\n",
    "classes = [0, 32] # track person and ball"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataloader\n",
    "from boxmot.yolo.utils.dataloaders import LoadStreams, LoadImages\n",
    "from boxmot.yolo.utils.torch_utils import select_device\n",
    "\n",
    "device = select_device(device)\n",
    "\n",
    "dataset = LoadImages(source, img_size=640, stride=32, auto=True)\n",
    "nr_frames = dataset.nf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Instanciate models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances\n",
    "yolo = YOLO(yolo_model)\n",
    "yolo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Run tracking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate trackers\n",
    "from boxmot import DeepOCSORT\n",
    "\n",
    "tracker = DeepOCSORT(\n",
    "    model_weights=Path('osnet_x0_25_msmt17.pt'), # which ReID model to use\n",
    "    device='cuda:0', # 'cpu', 'cuda:0', 'cuda:1', ...\n",
    "    fp16=True, # wether to run the ReID model with fp16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tracking_results = {}\n",
    "yolo_preds = []\n",
    "\n",
    "#for tracker_name, tracker in trackers.items():\n",
    "    \n",
    "frame_idx = 0\n",
    "all_tracks = []\n",
    "\n",
    "for frame in tqdm(dataset, desc=f'Processing frames for OCSORT', total=nr_frames):\n",
    "\n",
    "    # yolo detection\n",
    "    path, im, im0s, vid_cap, s = frame\n",
    "    # make detections \n",
    "    preds = yolo.predict(\n",
    "        im, \n",
    "        conf=conf, \n",
    "        iou=iou, \n",
    "        classes=classes,\n",
    "        verbose=False\n",
    "    )\n",
    "    yolo_preds.append(preds[0])\n",
    "\n",
    "    # track\n",
    "    tracks = tracker.update(preds[0].boxes.data.cpu(), im0s)\n",
    "    if tracks.size > 0:\n",
    "        # frame_idx, track_id, x, y, w, h, class_id, conf\n",
    "        all_tracks.append(np.concatenate((np.full((tracks.shape[0], 1), frame_idx), tracks), axis=1))\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "all_tracks = np.concatenate(all_tracks, axis=0)\n",
    "tracking_results['ocsort'] = all_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Generate Videos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tracking videos for visualization\n",
    "if 'tracking_results' in locals() and tracking_results and data_loader:\n",
    "    video_output_dir = '../output/videos'\n",
    "    ensure_dir(video_output_dir)\n",
    "\n",
    "    for tracker_name, all_tracks in tracking_results.items():\n",
    "        print(f'\\nGenerating video for {tracker_name} tracker...')\n",
    "\n",
    "        # Create annotated frames\n",
    "        annotated_frames = []\n",
    "        video_info = get_video_info(str(source))\n",
    "        colors = Colors()\n",
    "\n",
    "        for frame_idx, frame in enumerate(tqdm(data_loader, desc=f'Annotating frames for {tracker_name}', total=video_info['frame_count'])):\n",
    "\n",
    "            path, im, im0s, vid_cap, s = frame\n",
    "            annotator = Annotator(im0s, 2, \"Arial.ttf\")\n",
    "\n",
    "            # get tracks in this frame\n",
    "            frame_tracks = all_tracks[all_tracks[:, 0] == frame_idx]\n",
    "\n",
    "            # draw tracks\n",
    "            for t in frame_tracks:\n",
    "                track_id, x, y, w, h, cls, conf = t[1:]\n",
    "                # convert to top-left, bottom-right\n",
    "                xyxy = [x, y, x + w, y + h]\n",
    "                annotator.box_label(xyxy, f'{int(track_id)}', color=colors(int(cls), True))\n",
    "\n",
    "            annotated_frames.append(annotator.result())\n",
    "\n",
    "        # Write video\n",
    "        output_video_path = f'{video_output_dir}/{tracker_name}.mp4'\n",
    "        video_writer = create_video_writer(video_info, output_video_path)\n",
    "\n",
    "        for frame in tqdm(annotated_frames, desc=f'Writing video for {tracker_name}', total=len(annotated_frames)):\n",
    "            video_writer.write(frame)\n",
    "\n",
    "        video_writer.release()\n",
    "        print(f'Video for {tracker_name} tracker saved to {output_video_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4: Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Load GT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = Path('../data/gt/mot_challenge/ball-challenge-train/ball/gt/gt.txt')\n",
    "gt = mm.io.loadtxt(gt_path, fmt='mot15-2D')\n",
    "gt_df = gt.reset_index().set_index(['FrameId', 'Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Convert tracking results to MOT format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tracking results to the MOT format\n",
    "ts_df = pd.DataFrame(\n",
    "    all_tracks,\n",
    "    columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'ClassId', 'Conf']\n",
    ").set_index(['FrameId', 'Id'])\n",
    "\n",
    "# only evaluate on the ball class\n",
    "ts_df = ts_df[ts_df['ClassId'] == 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Run MOT evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "# iterate over all frames of the video\n",
    "for frame_id in tqdm(gt_df.index.get_level_values('FrameId').unique()):\n",
    "    \n",
    "    # get the gt and ts objects for the current frame\n",
    "    gt_frame = gt_df.loc[frame_id]\n",
    "    ts_frame = ts_df.loc[frame_id] if frame_id in ts_df.index.get_level_values('FrameId') else pd.DataFrame()\n",
    "    \n",
    "    # compute the distance between the gt and ts objects\n",
    "    C = mm.distances.iou_matrix(gt_frame[['X', 'Y', 'Width', 'Height']], ts_frame[['X', 'Y', 'Width', 'Height']], max_iou=0.5)\n",
    "    \n",
    "    # update the accumulator with the results for the current frame\n",
    "    acc.update(\n",
    "        gt_frame.index.get_level_values('Id').tolist(),\n",
    "        ts_frame.index.get_level_values('Id').tolist(),\n",
    "        C\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Get metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = mm.metrics.create()\n",
    "summary = mh.compute(\n",
    "    acc, \n",
    "    metrics=mm.metrics.motchallenge_metrics, \n",
    "    name='acc'\n",
    ")\n",
    "\n",
    "print(mm.io.render_summary(\n",
    "    summary, \n",
    "    formatters=mh.formatters, \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
